<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Segmentation Model-Part VII - Training Instance Segmentation in MMDetection | Hoang Phuong’ Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Segmentation Model-Part VII - Training Instance Segmentation in MMDetection" />
<meta name="author" content="Nguyen Hoang-Phuong" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The seventh part of the Segmentation Tutorial Series, a step-by-step guide to developing Instance Segmentation Models in MMDetection" />
<meta property="og:description" content="The seventh part of the Segmentation Tutorial Series, a step-by-step guide to developing Instance Segmentation Models in MMDetection" />
<link rel="canonical" href="https://hphuongdhsp.github.io/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/segformer/huggingface/2022/08/08/segmentation-model-part7.html" />
<meta property="og:url" content="https://hphuongdhsp.github.io/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/segformer/huggingface/2022/08/08/segmentation-model-part7.html" />
<meta property="og:site_name" content="Hoang Phuong’ Blog" />
<meta property="og:image" content="https://hphuongdhsp.github.io/ml-blog/images/mmdetection.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-08T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://hphuongdhsp.github.io/ml-blog/images/mmdetection.png" />
<meta property="twitter:title" content="Segmentation Model-Part VII - Training Instance Segmentation in MMDetection" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Nguyen Hoang-Phuong"},"dateModified":"2022-08-08T00:00:00-05:00","datePublished":"2022-08-08T00:00:00-05:00","description":"The seventh part of the Segmentation Tutorial Series, a step-by-step guide to developing Instance Segmentation Models in MMDetection","headline":"Segmentation Model-Part VII - Training Instance Segmentation in MMDetection","image":"https://hphuongdhsp.github.io/ml-blog/images/mmdetection.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://hphuongdhsp.github.io/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/segformer/huggingface/2022/08/08/segmentation-model-part7.html"},"url":"https://hphuongdhsp.github.io/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/segformer/huggingface/2022/08/08/segmentation-model-part7.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ml-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://hphuongdhsp.github.io/ml-blog/feed.xml" title="Hoang Phuong' Blog" /><link rel="shortcut icon" type="image/x-icon" href="/ml-blog/images/hp.ico">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/ml-blog/">Hoang Phuong&#39; Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/ml-blog/about/">About Me</a><a class="page-link" href="/ml-blog/search/">Search</a><a class="page-link" href="/ml-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Segmentation Model-Part VII -  Training Instance Segmentation in MMDetection</h1><p class="page-description">The seventh part of the Segmentation Tutorial Series, a step-by-step guide to developing Instance Segmentation Models in MMDetection</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-08T00:00:00-05:00" itemprop="datePublished">
        Aug 8, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Nguyen Hoang-Phuong</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      9 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/ml-blog/categories/#pytorchlightning">pytorchlightning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#semanticsegmentation">semanticsegmentation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#deeplearning">deeplearning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#segformer">segformer</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#huggingface">huggingface</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#1-semantic-segmentation-vs-instance-segmentation">1. Semantic Segmentation vs Instance Segmentation</a></li>
<li class="toc-entry toc-h2"><a href="#1-problem-description-and-dataset">1. Problem Description and Dataset</a></li>
<li class="toc-entry toc-h2"><a href="#2-data-preparation">2. Data Preparation</a>
<ul>
<li class="toc-entry toc-h3"><a href="#21-make-data-frame">2.1 Make data frame</a></li>
<li class="toc-entry toc-h3"><a href="#22-get-coco-annotation">2.2 Get coco annotation</a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#3-training-instance-segmentation-problems-by-mmdetection">3. Training instance segmentation problems by MMDetection</a>
<ul>
<li class="toc-entry toc-h3"><a href="#31-mmdetection">3.1 MMDetection</a></li>
<li class="toc-entry toc-h3"><a href="#32-modify-the-config">3.2 Modify the config.</a>
<ul>
<li class="toc-entry toc-h4"><a href="#modify-the-model-config">Modify the model config</a></li>
<li class="toc-entry toc-h4"><a href="#modify-the-data-pipeline-config">Modify the data pipeline config</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#32-training">3.2 Training</a>
<ul>
<li class="toc-entry toc-h4"><a href="#import-config-by-using-mmcv-library">Import Config by using mmcv library:</a></li>
<li class="toc-entry toc-h4"><a href="#build-the-model-pipeline-from-the-config-by-using-build_detector-api">Build the model pipeline from the Config by using build_detector api</a></li>
<li class="toc-entry toc-h4"><a href="#build-the-data-pipeline-from-the-config-by-using-build_dataset-api">Build the data pipeline from the Config by using build_dataset api</a></li>
<li class="toc-entry toc-h4"><a href="#train-the-model-with-the-train_detector-api">Train the model with the train_detector api</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#references">References</a></li>
</ul>
</li>
</ul><p>In this post, we will cover how to train a instance segmentation model by using the MMDetection library.</p>

<h2 id="1-semantic-segmentation-vs-instance-segmentation">
<a class="anchor" href="#1-semantic-segmentation-vs-instance-segmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Semantic Segmentation vs Instance Segmentation</h2>

<p>We first introduce about: Semantic image segmentation, Object detection, Semantic Image segmentation</p>

<ul>
  <li>A Semantic image segmentation marks all pixels belonging to that tag, but won’t define the boundaries of each object.</li>
  <li>A Object detection does not segment the object, but define the location of each individual object instance with a box.</li>
  <li>Combining the semantic segmentation with the object detection leads to a instance segmentation</li>
</ul>

<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/uc/uw/sy/ucuwsy-0vb8vjqw0v_9gviyv-ga.jpeg"> -->

<p><img src="https://habrastorage.org/webt/uc/uw/sy/ucuwsy-0vb8vjqw0v_9gviyv-ga.jpeg" alt="" title="Instace Segmentation ,Source: V7Lab"></p>

<p>Nowaday, to tackle the instance segmentation problem, one use uselly <a href="https://arxiv.org/pdf/1703.06870.pdf">Mask R-CNN model</a> which is presented by [K.He] and all.  For more detail about Mask R-CNN model, we  refer to read <a href="https://viso.ai/deep-learning/mask-r-cnn/#:~:text=Mask%20R%2DCNN%20is%20a,segmentation%20mask%20for%20each%20instance.">Everything about Mask R-CNN: A Beginner’s Guide</a> artical.</p>

<p><strong>Mask R-CNN</strong> is the state-of-the-art model for the Instance Segmentation with three outputs of the model: mask, classes and boundary box.</p>

<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/kg/sg/eb/kgsgebllp-5ajlord4ikausbzle.png"> -->
<p><img src="https://habrastorage.org/webt/kg/sg/eb/kgsgebllp-5ajlord4ikausbzle.png" alt="" title="Mask R-CNN architechture,Source: V7Lab"></p>

<h2 id="1-problem-description-and-dataset">
<a class="anchor" href="#1-problem-description-and-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Problem Description and Dataset</h2>

<p>We will cover the nail instance segmentation. We want to have a bounding box and segment each nail in the picture. It’s from the real application. We want to make a nail disease classification application. To do that, the first step is cropping nails in the given image. Then each cropping nail image will be fed in to the classification model.</p>

<p>For the semantic nail segmentation, we can segment the nail in iamges and then use post-processing to obtain the bounding box and segmentation of nails. That method does not work well in the case that the nails have overlapping. We then aproach the instance segmentation problem to tackle the difficulty.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Images</th>
      <th style="text-align: center">Masks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img align="center" width="300" src="https://habrastorage.org/webt/em/og/9v/emog9v4ya7ssllg5dht77_wehqk.png"></td>
      <td style="text-align: center"><img align="center" width="300" src="https://habrastorage.org/webt/hl/bf/ov/hlbfovx1uhrbbebgxndyho9yywo.png"></td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>Mission:  <strong>We want to have a bounding box and segmentation of each nail in the picture.</strong></p>
</blockquote>

<p>Our data is organized as</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── Images
│   ├── 1
│       ├── first_image.png
│       ├── second_image.png
│       ├── third_image.png
│   ├── 2
│   ├── 3
│   ├── 4
├── Masks
│   ├── 1
│       ├── first_image.png
│       ├── second_image.png
│       ├── third_image.png
│   ├── 2
│   ├── 3
│   ├── 4

</code></pre></div></div>

<p>We have two folders: <code class="language-plaintext highlighter-rouge">Images</code> and <code class="language-plaintext highlighter-rouge">Masks</code>. <code class="language-plaintext highlighter-rouge">Images</code> is the data folder, and <code class="language-plaintext highlighter-rouge">Masks</code> is the label folder, which is the segmentations of input images. Each folder has four sub-folder:  <code class="language-plaintext highlighter-rouge">1</code>, <code class="language-plaintext highlighter-rouge">2</code>, <code class="language-plaintext highlighter-rouge">3</code>, and <code class="language-plaintext highlighter-rouge">4</code>, corresponding to four types of nail distribution.</p>

<p>We download data from <a href="https://drive.google.com/file/d/1qBLwdQeu9nvTw70E46XNXMciB0aKsM7r/view?usp=sharing">link</a> and put it in <code class="language-plaintext highlighter-rouge">data_root</code>, for example</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_root</span> <span class="o">=</span> <span class="s">"./nail-segmentation-dataset"</span>
</code></pre></div></div>

<h2 id="2-data-preparation">
<a class="anchor" href="#2-data-preparation" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Data Preparation</h2>

<p>We now have only the semantic segmentation dataset. This part we will make the instance segmentation datset and save that data in the form <code class="language-plaintext highlighter-rouge">coco</code>.</p>

<h3 id="21-make-data-frame">
<a class="anchor" href="#21-make-data-frame" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.1 Make data frame</h3>

<p>For convenient, we will save all of dataset information in the csv files:</p>

<p>images,masks,width,height</p>

<table>
  <thead>
    <tr>
      <th>images</th>
      <th>masks</th>
      <th>width</th>
      <th>height</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>images/1/filename1.png</td>
      <td>masks/1/filename1.png</td>
      <td>256</td>
      <td>256</td>
    </tr>
    <tr>
      <td>images/1/filename1.png</td>
      <td>masks/1/filename1.png</td>
      <td>256</td>
      <td>256</td>
    </tr>
    <tr>
      <td>images/2/filename1.png</td>
      <td>masks/2/filename1.png</td>
      <td>256</td>
      <td>256</td>
    </tr>
    <tr>
      <td>images/2/filename1.png</td>
      <td>masks/2/filename1.png</td>
      <td>256</td>
      <td>256</td>
    </tr>
  </tbody>
</table>

<p>The function <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/blob/master/Part%207-Instance%20Segmentation%20with%20MMDetection/data_preprocessing.py"><code class="language-plaintext highlighter-rouge">make_csv_file</code></a> helps us do the above task.</p>

<p>To do that we use two functions <code class="language-plaintext highlighter-rouge">png2numpy</code>, <code class="language-plaintext highlighter-rouge">make_csv_file_npy</code> in <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/blob/master/Part%205-Pytorch%20with%20Dali/data_processing.py"><code class="language-plaintext highlighter-rouge">data_processing.py</code></a> file.</p>

<h3 id="22-get-coco-annotation">
<a class="anchor" href="#22-get-coco-annotation" aria-hidden="true"><span class="octicon octicon-link"></span></a>2.2 Get coco annotation</h3>

<p>We want to convert our semantic segmentation data into the instance segmentaion. One of the famous format to organize the instance segmentation data is <code class="language-plaintext highlighter-rouge">COCO</code>.</p>

<p>The coco annotation has the following format</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span>
    <span class="s">"images"</span><span class="p">:</span> <span class="p">[</span><span class="n">images</span><span class="p">],</span>
    <span class="s">"annotations"</span><span class="p">:</span> <span class="p">[</span><span class="n">annotations</span><span class="p">],</span>
    <span class="s">"categories"</span><span class="p">:</span> <span class="p">[</span><span class="n">categories</span><span class="p">]</span>
<span class="p">}</span>
</code></pre></div></div>

<p>Where:</p>

<ul>
  <li>
<strong>“images”</strong> (type: [List[Dict]]) is the list of dictionaries, each dictionary has informations
    <ul>
      <li>“id”: 100   The id of image</li>
      <li>“file_name”: “train/images/1/image_100.png”,  the path to get image</li>
      <li>“width”: 1800,</li>
      <li>“height”: 1626</li>
    </ul>
  </li>
  <li>
    <p><strong>“annotations”</strong>  is the list of dictionaries, each dictionary has informations</p>

    <ul>
      <li>“id”: 350, id of object (not the image id)</li>
      <li>“image_id”: 100, id of image</li>
      <li>“category_id”: 1, id of categories</li>
      <li>“segmentation”: RLE or [polygon],</li>
      <li>“area”: float,</li>
      <li>“bbox”: [x,y,width,height],</li>
      <li>“iscrowd”: 0 or 1,</li>
    </ul>
  </li>
  <li>
<strong>“categories”</strong>  is the list of dictionaries, each dictionary has informations
    <ul>
      <li>“id”: int = 0 id of categories</li>
      <li>“name”: str = “nail”</li>
    </ul>
  </li>
</ul>

<p>Using the <em>get_annotations</em> function, we can convert the semantic segmentation data into the coco format data of the instance segmentation.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_annotations</span><span class="p">(</span><span class="n">dataframe</span><span class="p">:</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">):</span>
    <span class="s">"""get_annotations is to convert a dataframe into the coco format

    Args:
        train_df (pd.DataFrame): the dataframe that stored the infomation
        of the dataset. the form of the dataframe is
        images | width | height |

    Returns:
        [type]: the coco format data of the dataset
    """</span>

    <span class="n">cats</span> <span class="o">=</span> <span class="p">[{</span><span class="s">"id"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"name"</span><span class="p">:</span> <span class="s">"nail"</span><span class="p">}]</span>

    <span class="n">annotations</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">obj_count</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">row</span> <span class="ow">in</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">dataframe</span><span class="p">.</span><span class="n">iterrows</span><span class="p">(),</span> <span class="n">total</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">dataframe</span><span class="p">)):</span>
        <span class="n">filename</span> <span class="o">=</span> <span class="n">row</span><span class="p">.</span><span class="n">images</span>

        <span class="n">images</span><span class="p">.</span><span class="n">append</span><span class="p">(</span>
            <span class="p">{</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">idx</span><span class="p">,</span>
                <span class="s">"file_name"</span><span class="p">:</span> <span class="n">filename</span><span class="p">,</span>
                <span class="s">"width"</span><span class="p">:</span> <span class="n">row</span><span class="p">.</span><span class="n">width</span><span class="p">,</span>
                <span class="s">"height"</span><span class="p">:</span> <span class="n">row</span><span class="p">.</span><span class="n">height</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">)</span>

        <span class="n">binary_mask</span> <span class="o">=</span> <span class="n">read_mask</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="nb">str</span><span class="p">(</span><span class="n">data_root</span><span class="p">),</span> <span class="n">row</span><span class="p">.</span><span class="n">masks</span><span class="p">))</span>

        <span class="n">contours</span> <span class="o">=</span> <span class="n">find_contours</span><span class="p">(</span><span class="n">binary_mask</span><span class="p">)</span>

        <span class="k">for</span> <span class="n">contour</span> <span class="ow">in</span> <span class="n">contours</span><span class="p">:</span>
            <span class="n">xmin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">contour</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]))</span>
            <span class="n">xmax</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">contour</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">]))</span>
            <span class="n">ymin</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">contour</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]))</span>
            <span class="n">ymax</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">contour</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">]))</span>

            <span class="n">poly</span> <span class="o">=</span> <span class="n">contour</span><span class="p">.</span><span class="n">flatten</span><span class="p">().</span><span class="n">tolist</span><span class="p">()</span>
            <span class="n">poly</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="o">+</span> <span class="mf">0.5</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">poly</span><span class="p">]</span>

            <span class="n">data_anno</span> <span class="o">=</span> <span class="p">{</span>
                <span class="s">"image_id"</span><span class="p">:</span> <span class="n">idx</span><span class="p">,</span>
                <span class="s">"id"</span><span class="p">:</span> <span class="n">obj_count</span><span class="p">,</span>
                <span class="s">"category_id"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
                <span class="s">"bbox"</span><span class="p">:</span> <span class="p">[</span><span class="n">xmin</span><span class="p">,</span> <span class="n">ymin</span><span class="p">,</span> <span class="p">(</span><span class="n">xmax</span> <span class="o">-</span> <span class="n">xmin</span><span class="p">),</span> <span class="p">(</span><span class="n">ymax</span> <span class="o">-</span> <span class="n">ymin</span><span class="p">)],</span>
                <span class="s">"area"</span><span class="p">:</span> <span class="p">(</span><span class="n">xmax</span> <span class="o">-</span> <span class="n">xmin</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">ymax</span> <span class="o">-</span> <span class="n">ymin</span><span class="p">),</span>
                <span class="s">"segmentation"</span><span class="p">:</span> <span class="p">[</span><span class="n">poly</span><span class="p">],</span>
                <span class="s">"iscrowd"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="p">}</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">xmax</span> <span class="o">-</span> <span class="n">xmin</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="n">ymax</span> <span class="o">-</span> <span class="n">ymin</span><span class="p">)</span> <span class="o">&lt;</span> <span class="mi">20</span><span class="p">:</span>
                <span class="k">continue</span>

            <span class="k">else</span><span class="p">:</span>
                <span class="n">annotations</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">data_anno</span><span class="p">)</span>

                <span class="n">obj_count</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="k">return</span> <span class="p">{</span><span class="s">"categories"</span><span class="p">:</span> <span class="n">cats</span><span class="p">,</span> <span class="s">"images"</span><span class="p">:</span> <span class="n">images</span><span class="p">,</span> <span class="s">"annotations"</span><span class="p">:</span> <span class="n">annotations</span><span class="p">}</span>

</code></pre></div></div>

<p>Where:</p>

<ul>
  <li>
<em>find_contours</em> is a function to get contour of a binary mask.</li>
  <li>dataframe argument of the above function is the data frame obtained from the <em>make_csv_file</em> that has the infomations of data.</li>
</ul>

<p>We then save the annotaions as a json file by the <code class="language-plaintext highlighter-rouge">get_json_coco</code> function</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def get_json_coco(args) -&gt; None:
    train_df = pd.read_csv(f"{data_root}/csv_file/train_info.csv")
    valid_df = pd.read_csv(f"{data_root}/csv_file/valid_info.csv")

    coco_json = os.path.join(data_root, "annotations")
    mkdir(coco_json)
    train_json = get_annotations(train_df)
    valid_json = get_annotations(valid_df)

    with open(f"{coco_json}/train.json", "w+", encoding="utf-8") as f:
        json.dump(train_json, f, ensure_ascii=True, indent=4)
    with open(f"{coco_json}/valid.json", "w+", encoding="utf-8") as f:
        json.dump(valid_json, f, ensure_ascii=True, indent=4)

</code></pre></div></div>

<p><strong>For more details, we can find the source code at <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/tree/master/Part%205-Pytorch%20with%20Dali">github</a></strong></p>

<h2 id="3-training-instance-segmentation-problems-by-mmdetection">
<a class="anchor" href="#3-training-instance-segmentation-problems-by-mmdetection" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Training instance segmentation problems by MMDetection</h2>

<h3 id="31-mmdetection">
<a class="anchor" href="#31-mmdetection" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1 MMDetection</h3>

<p><strong>MMDetection</strong> is an object detection toolbox that contains a rich set of object detection and instance segmentation methods as well as related components and modules. It is built on top of PyTorch.</p>

<p>One decomposes the detection framework into different components and one can easily construct a customized object detection framework by combining different modules. In this part, we discover how to decompose  the instance segmentation framework and modify them in order to train a instance segmentation model.</p>

<p>To train a instance segmentation or object detection model, we pass to three steps:</p>

<ul>
  <li>Prepare the customized dataset</li>
  <li>Prepare a config</li>
  <li>Train, test, inference models on the customized dataset.</li>
</ul>

<p>In the second part we have customized our dataset into the coco format. With the coco format, we can easy reuse configurations.</p>

<h3 id="32-modify-the-config">
<a class="anchor" href="#32-modify-the-config" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2 Modify the config.</h3>

<blockquote>
  <p><strong>Config is all we need</strong></p>
</blockquote>

<p>To run a instance segmentation or object detection, all we need to do is define a good config. In the config file, there are all of infomation for a training model.</p>

<p>Examples of configurations are given in <a href="https://github.com/open-mmlab/mmdetection/tree/master/configs">config</a>. There are a lot of configs that help to build a customized configs. For the convenience, we will download them and put them to the repository of <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/tree/master/Part%207-Instance%20Segmentation%20with%20MMDetection">MMDetection tutorial</a>.</p>

<p>A Config can be decompose into four parts.</p>

<ul>
  <li>model: define the model architechture, loss function</li>
  <li>dataset: define the data pipeline</li>
  <li>schedules: define the optimization and the schedules learning rate</li>
  <li>default_runtime: define the logging, check point.</li>
</ul>

<p>In the <code class="language-plaintext highlighter-rouge">configs/__base__</code> there are examples for each module</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── configs
│   ├── __base__
│       ├── datasets
│       ├── models
│       ├── schedules
│       ├── default_runtime.py
</code></pre></div></div>

<p>Also, inside of the <code class="language-plaintext highlighter-rouge">configs</code>, we have alot of subconfigs that coresponding to the model acrchitecture.</p>

<p>For example:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>configs/mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py

</code></pre></div></div>

<p>Here</p>
<ul>
  <li>mask_rcnn: type of mask_rcnn</li>
  <li>r50: backbone of the model (Resnet50)</li>
  <li>caffe: the pretrained model is caffe model.</li>
  <li>fpn: the feature pyramid network.</li>
  <li>mstrain: the multi-scale image for the data pipeline</li>
  <li>poly: schedule poly</li>
  <li>1x: 12 max_epochs</li>
  <li>coco: the dataset is coco format.</li>
</ul>

<p>In this post, we focus on two modules: dataset and model and set the <em>schedules</em> and <em>default_runtime</em> as default.</p>

<h4 id="modify-the-model-config">
<a class="anchor" href="#modify-the-model-config" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modify the model config</h4>

<p>With the nail segmentation, the output is a binary mask (only nail object), then redefine the model as:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># The new config inherits a base config to highlight the necessary modification
</span><span class="n">_base_</span> <span class="o">=</span> <span class="s">"mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py"</span>

<span class="c1"># We also need to change the num_classes in head to match the dataset's annotation
</span><span class="n">model</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">roi_head</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">bbox_head</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span> <span class="n">mask_head</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span><span class="n">num_classes</span><span class="o">=</span><span class="mi">1</span><span class="p">)))</span>

</code></pre></div></div>
<p>Here:</p>

<ul>
  <li>We inherit the config <code class="language-plaintext highlighter-rouge">mask_rcnn/mask_rcnn_r50_caffe_fpn_mstrain-poly_1x_coco.py</code>
</li>
  <li>Only need to define the num_classes in the bbox_head and mask_head.</li>
</ul>

<h4 id="modify-the-data-pipeline-config">
<a class="anchor" href="#modify-the-data-pipeline-config" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modify the data pipeline config</h4>

<p>For the data pipeline:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
    <span class="n">samples_per_gpu</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">workers_per_gpu</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="n">train</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="nb">type</span><span class="o">=</span><span class="s">"CocoDataset"</span><span class="p">,</span>
        <span class="n">img_prefix</span><span class="o">=</span><span class="n">data_root</span><span class="p">,</span>
        <span class="n">classes</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">classes</span><span class="p">,</span>
        <span class="n">ann_file</span><span class="o">=</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">data_root</span><span class="si">}</span><span class="s">/annotations/train.json"</span><span class="p">,</span>
        <span class="n">pipeline</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">train_pipeline</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">val</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="nb">type</span><span class="o">=</span><span class="s">"CocoDataset"</span><span class="p">,</span>
        <span class="n">img_prefix</span><span class="o">=</span><span class="n">data_root</span><span class="p">,</span>
        <span class="n">classes</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">classes</span><span class="p">,</span>
        <span class="n">ann_file</span><span class="o">=</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">data_root</span><span class="si">}</span><span class="s">/annotations/valid.json"</span><span class="p">,</span>
        <span class="n">pipeline</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">test_pipeline</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="n">test</span><span class="o">=</span><span class="nb">dict</span><span class="p">(</span>
        <span class="nb">type</span><span class="o">=</span><span class="s">"CocoDataset"</span><span class="p">,</span>
        <span class="n">img_prefix</span><span class="o">=</span><span class="n">data_root</span><span class="p">,</span>
        <span class="n">classes</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">classes</span><span class="p">,</span>
        <span class="n">ann_file</span><span class="o">=</span><span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">data_root</span><span class="si">}</span><span class="s">/annotations/valid.json"</span><span class="p">,</span>
        <span class="n">pipeline</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">test_pipeline</span><span class="p">,</span>
    <span class="p">),</span>
<span class="p">)</span>

</code></pre></div></div>

<p>Here:</p>
<ul>
  <li>type:”CocoDataset” as default because we use the coco format.</li>
  <li>img_prefix: - the path to the image directory.</li>
  <li>ann_file: the path to the json annotation file.</li>
  <li>classes: the classes of the dataset. Here class: = [“nail”]</li>
  <li>pipeline: data pipeline processing that is defined as</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">train_pipeline</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"LoadImageFromFile"</span><span class="p">),</span>
    <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"LoadAnnotations"</span><span class="p">,</span> <span class="n">with_bbox</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">with_mask</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
    <span class="nb">dict</span><span class="p">(</span>
        <span class="nb">type</span><span class="o">=</span><span class="s">"Resize"</span><span class="p">,</span>
        <span class="n">img_scale</span><span class="o">=</span><span class="p">[(</span><span class="mi">1333</span><span class="p">,</span> <span class="mi">640</span><span class="p">),</span> <span class="p">(</span><span class="mi">1333</span><span class="p">,</span> <span class="mi">672</span><span class="p">),</span> <span class="p">(</span><span class="mi">1333</span><span class="p">,</span> <span class="mi">704</span><span class="p">),</span> <span class="p">(</span><span class="mi">1333</span><span class="p">,</span> <span class="mi">736</span><span class="p">),</span> <span class="p">(</span><span class="mi">1333</span><span class="p">,</span> <span class="mi">768</span><span class="p">),</span> <span class="p">(</span><span class="mi">1333</span><span class="p">,</span> <span class="mi">800</span><span class="p">)],</span>
        <span class="n">multiscale_mode</span><span class="o">=</span><span class="s">"value"</span><span class="p">,</span>
        <span class="n">keep_ratio</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="p">),</span>
    <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"RandomFlip"</span><span class="p">,</span> <span class="n">flip_ratio</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"Normalize"</span><span class="p">,</span> <span class="o">**</span><span class="n">img_norm_cfg</span><span class="p">),</span>
    <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"Pad"</span><span class="p">,</span> <span class="n">size_divisor</span><span class="o">=</span><span class="mi">32</span><span class="p">),</span>
    <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"DefaultFormatBundle"</span><span class="p">),</span>
    <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"Collect"</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s">"img"</span><span class="p">,</span> <span class="s">"gt_bboxes"</span><span class="p">,</span> <span class="s">"gt_labels"</span><span class="p">,</span> <span class="s">"gt_masks"</span><span class="p">]),</span>
<span class="p">]</span>
<span class="n">test_pipeline</span> <span class="o">=</span> <span class="p">[</span>
    <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"LoadImageFromFile"</span><span class="p">),</span>
    <span class="nb">dict</span><span class="p">(</span>
        <span class="nb">type</span><span class="o">=</span><span class="s">"MultiScaleFlipAug"</span><span class="p">,</span>
        <span class="n">img_scale</span><span class="o">=</span><span class="p">(</span><span class="mi">1333</span><span class="p">,</span> <span class="mi">800</span><span class="p">),</span>
        <span class="n">flip</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="n">transforms</span><span class="o">=</span><span class="p">[</span>
            <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"Resize"</span><span class="p">,</span> <span class="n">keep_ratio</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"RandomFlip"</span><span class="p">),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"Normalize"</span><span class="p">,</span> <span class="o">**</span><span class="n">img_norm_cfg</span><span class="p">),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"Pad"</span><span class="p">,</span> <span class="n">size_divisor</span><span class="o">=</span><span class="mi">32</span><span class="p">),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"ImageToTensor"</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s">"img"</span><span class="p">]),</span>
            <span class="nb">dict</span><span class="p">(</span><span class="nb">type</span><span class="o">=</span><span class="s">"Collect"</span><span class="p">,</span> <span class="n">keys</span><span class="o">=</span><span class="p">[</span><span class="s">"img"</span><span class="p">]),</span>
        <span class="p">],</span>
    <span class="p">),</span>
<span class="p">]</span>
</code></pre></div></div>
<blockquote>
  <p>Note: we want use the multi-scale image when training the pipeline, then</p>
</blockquote>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>img_scale=[(1333, 640), (1333, 672), (1333, 704), (1333, 736), (1333, 768), (1333, 800)]

</code></pre></div></div>
<h3 id="32-training">
<a class="anchor" href="#32-training" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2 Training</h3>

<p>Once we have the config file (see [nail_conig.py], we start to train model.</p>

<p>For that we will:</p>
<ul>
  <li>import the config file</li>
  <li>define the model module</li>
  <li>defime the data pipeline</li>
  <li>train the model with an api</li>
</ul>

<h4 id="import-config-by-using-mmcv-library">
<a class="anchor" href="#import-config-by-using-mmcv-library" aria-hidden="true"><span class="octicon octicon-link"></span></a>Import Config by using <code class="language-plaintext highlighter-rouge">mmcv</code> library:</h4>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cfg = mmcv.Config("configs/nail_config.py")
</code></pre></div></div>

<h4 id="build-the-model-pipeline-from-the-config-by-using-build_detector-api">
<a class="anchor" href="#build-the-model-pipeline-from-the-config-by-using-build_detector-api" aria-hidden="true"><span class="octicon octicon-link"></span></a>Build the model pipeline from the Config by using build_detector api</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">mmdet.apis</span> <span class="kn">import</span> <span class="n">build_detector</span>

<span class="n">model</span> <span class="o">=</span> <span class="n">build_detector</span><span class="p">(</span><span class="n">cfg</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> <span class="n">train_cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"train_cfg"</span><span class="p">),</span> <span class="n">test_cfg</span><span class="o">=</span><span class="n">cfg</span><span class="p">.</span><span class="n">get</span><span class="p">(</span><span class="s">"test_cfg"</span><span class="p">))</span>
<span class="n">model</span><span class="p">.</span><span class="n">init_weights</span><span class="p">()</span>

</code></pre></div></div>

<h4 id="build-the-data-pipeline-from-the-config-by-using-build_dataset-api">
<a class="anchor" href="#build-the-data-pipeline-from-the-config-by-using-build_dataset-api" aria-hidden="true"><span class="octicon octicon-link"></span></a>Build the data pipeline from the Config by using build_dataset api</h4>
<p>Using the apis: <code class="language-plaintext highlighter-rouge">build_detector</code>, <code class="language-plaintext highlighter-rouge">build_dataset</code> of mmdetection library, we can easily build the model and dataset.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>from mmdet.apis import build_dataset
datasets = [build_dataset(cfg.data.train)]
</code></pre></div></div>

<h4 id="train-the-model-with-the-train_detector-api">
<a class="anchor" href="#train-the-model-with-the-train_detector-api" aria-hidden="true"><span class="octicon octicon-link"></span></a>Train the model with the train_detector api</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">mmdet.apis</span> <span class="kn">import</span> <span class="n">train_detector</span>
<span class="n">train_detector</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">datasets</span><span class="p">)</span>

</code></pre></div></div>

<p>After 40 epochs, we can see the model is training well.</p>

<!-- <img align="center" width="400"  src="https://habrastorage.org/webt/q1/5v/hw/q15vhwbx5bslvd97sfhpca1iffu.jpeg"> -->

<p><img src="https://habrastorage.org/webt/q1/5v/hw/q15vhwbx5bslvd97sfhpca1iffu.jpeg" alt="" title="a result apter training 40 epochs"></p>

<p><strong>For more details, we can find the source code at <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/tree/master/Part%207-Instance%20Segmentation%20with%20MMDetection">github</a></strong></p>

<h3 id="references">
<a class="anchor" href="#references" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h3>

<ul>
  <li><a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/tree/master/Part%207-Instance%20Segmentation%20with%20MMDetection">Part 7-Instance Segmentation with MMDetection</a></li>
  <li><a href="https://mmdetection.readthedocs.io/en/stable/2_new_data_model.html#train-with-customized-datasets">MMDetection Tutorial - TRAIN WITH CUSTOMIZED DATASETS</a></li>
</ul>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="hphuongdhsp/ml-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/segformer/huggingface/2022/08/08/segmentation-model-part7.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ml-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/ml-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/ml-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>share2learn machine learning blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/hphuongdhsp" target="_blank" title="hphuongdhsp"><svg class="svg-icon grey"><use xlink:href="/ml-blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/hphuongdhsp" target="_blank" title="hphuongdhsp"><svg class="svg-icon grey"><use xlink:href="/ml-blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
