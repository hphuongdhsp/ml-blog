<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Segmentation Model-Part V - Data augmentation on the GPU with DALI | Hoang Phuong’ Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Segmentation Model-Part V - Data augmentation on the GPU with DALI" />
<meta name="author" content="Nguyen Hoang-Phuong" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The fifth part of the Segmentation Tutorial Series, a step-by-step guide to developing data augmentation on GPU with Dali library" />
<meta property="og:description" content="The fifth part of the Segmentation Tutorial Series, a step-by-step guide to developing data augmentation on GPU with Dali library" />
<link rel="canonical" href="https://hphuongdhsp.github.io/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/dali/2022/08/06/segmentation-model-part5.html" />
<meta property="og:url" content="https://hphuongdhsp.github.io/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/dali/2022/08/06/segmentation-model-part5.html" />
<meta property="og:site_name" content="Hoang Phuong’ Blog" />
<meta property="og:image" content="https://hphuongdhsp.github.io/ml-blog/images/dali.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-06T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://hphuongdhsp.github.io/ml-blog/images/dali.png" />
<meta property="twitter:title" content="Segmentation Model-Part V - Data augmentation on the GPU with DALI" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Nguyen Hoang-Phuong"},"dateModified":"2022-08-06T00:00:00-05:00","datePublished":"2022-08-06T00:00:00-05:00","description":"The fifth part of the Segmentation Tutorial Series, a step-by-step guide to developing data augmentation on GPU with Dali library","headline":"Segmentation Model-Part V - Data augmentation on the GPU with DALI","image":"https://hphuongdhsp.github.io/ml-blog/images/dali.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://hphuongdhsp.github.io/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/dali/2022/08/06/segmentation-model-part5.html"},"url":"https://hphuongdhsp.github.io/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/dali/2022/08/06/segmentation-model-part5.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ml-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://hphuongdhsp.github.io/ml-blog/feed.xml" title="Hoang Phuong' Blog" /><link rel="shortcut icon" type="image/x-icon" href="/ml-blog/images/hp.ico">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/ml-blog/">Hoang Phuong&#39; Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/ml-blog/about/">About Me</a><a class="page-link" href="/ml-blog/search/">Search</a><a class="page-link" href="/ml-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Segmentation Model-Part V - Data augmentation on the GPU with DALI</h1><p class="page-description">The fifth part of the Segmentation Tutorial Series, a step-by-step guide to developing data augmentation on GPU with Dali library</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-06T00:00:00-05:00" itemprop="datePublished">
        Aug 6, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Nguyen Hoang-Phuong</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      8 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/ml-blog/categories/#pytorchlightning">pytorchlightning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#semanticsegmentation">semanticsegmentation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#deeplearning">deeplearning</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#dali">dali</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#1-problem-description-and-dataset">1. Problem Description and Dataset</a></li>
<li class="toc-entry toc-h2"><a href="#2-data-preparation">2. Data Preparation</a></li>
<li class="toc-entry toc-h2"><a href="#3-nvidia-data-loading-library-dali">3. NVIDIA Data Loading Library (DALI)</a></li>
<li class="toc-entry toc-h2"><a href="#4-training-the-segmentation-problem-with-dali-and-pytorch-lighiting">4. Training the Segmentation problem with DALI and Pytorch Lighiting.</a>
<ul>
<li class="toc-entry toc-h3"><a href="#41-define-data-pipeline-by-dali">4.1 Define Data Pipeline by DALI</a>
<ul>
<li class="toc-entry toc-h4"><a href="#validpipeline">ValidPipeline</a></li>
<li class="toc-entry toc-h4"><a href="#trainpipeline">TrainPipeline</a></li>
</ul>
</li>
<li class="toc-entry toc-h3"><a href="#42-lightningwrapper">4.2 LightningWrapper</a></li>
<li class="toc-entry toc-h3"><a href="#references">References</a></li>
</ul>
</li>
</ul><p>In the last post, we have discovered how to augmente data on GPUs with Kornia. This post, we will 
we discover how to use <a href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html">DALI</a> to accelerate deep learning.</p>

<p>We will work with the Segmentation Problem (Nail Segmentation). For that, we use Pytorch Lightninig to train model and use <code class="language-plaintext highlighter-rouge">DALI</code> to load data and do data processing. In the first and second parts we will recall <code class="language-plaintext highlighter-rouge">Problem Description and Dataset</code>. If you have followed previous posts, you can skip that part.</p>

<h2 id="1-problem-description-and-dataset">
<a class="anchor" href="#1-problem-description-and-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Problem Description and Dataset</h2>

<p>We want to cover a nail semantic segmentation problem. For each image, we want to detect the segmentation of the nail in the image.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Images</th>
      <th style="text-align: center">Masks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img align="center" width="300" src="https://habrastorage.org/webt/em/og/9v/emog9v4ya7ssllg5dht77_wehqk.png"></td>
      <td style="text-align: center"><img align="center" width="300" src="https://habrastorage.org/webt/hl/bf/ov/hlbfovx1uhrbbebgxndyho9yywo.png"></td>
    </tr>
  </tbody>
</table>

<p>Our data is organized as</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── Images
│   ├── 1
│       ├── first_image.png
│       ├── second_image.png
│       ├── third_image.png
│   ├── 2
│   ├── 3
│   ├── 4
├── Masks
│   ├── 1
│       ├── first_image.png
│       ├── second_image.png
│       ├── third_image.png
│   ├── 2
│   ├── 3
│   ├── 4

</code></pre></div></div>

<p>We have two folders: <code class="language-plaintext highlighter-rouge">Images</code> and <code class="language-plaintext highlighter-rouge">Masks</code>. <code class="language-plaintext highlighter-rouge">Images</code> is the data folder, and <code class="language-plaintext highlighter-rouge">Masks</code> is the label folder, which is the segmentations of input images. Each folder has four sub-folder:  <code class="language-plaintext highlighter-rouge">1</code>, <code class="language-plaintext highlighter-rouge">2</code>, <code class="language-plaintext highlighter-rouge">3</code>, and <code class="language-plaintext highlighter-rouge">4</code>, corresponding to four types of nail distribution.</p>

<p>We download data from <a href="https://drive.google.com/file/d/1qBLwdQeu9nvTw70E46XNXMciB0aKsM7r/view?usp=sharing">link</a> and put it in <code class="language-plaintext highlighter-rouge">data_root</code>, for example</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_root</span> <span class="o">=</span> <span class="s">"./nail-segmentation-dataset"</span>
</code></pre></div></div>

<h2 id="2-data-preparation">
<a class="anchor" href="#2-data-preparation" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Data Preparation</h2>

<p>For the convenience of training with DALI, we will convert <code class="language-plaintext highlighter-rouge">png</code> data into <code class="language-plaintext highlighter-rouge">npy</code> format and save all of informations of images and masks in a CSV file</p>

<table>
  <thead>
    <tr>
      <th>index</th>
      <th>images</th>
      <th>masks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>path_first_image.npy</td>
      <td>path_first_image.npy</td>
    </tr>
    <tr>
      <td>2</td>
      <td>path_second_image.npy</td>
      <td>path_second_image.npy</td>
    </tr>
    <tr>
      <td>3</td>
      <td>path_third_image.npy</td>
      <td>path_third_image.npy</td>
    </tr>
    <tr>
      <td>4</td>
      <td>path_fourth_image.npy</td>
      <td>path_fourth_image.npy</td>
    </tr>
  </tbody>
</table>

<p>To do that we use two functions <code class="language-plaintext highlighter-rouge">png2numpy</code>, <code class="language-plaintext highlighter-rouge">make_csv_file_npy</code> in <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/blob/master/Part%205-Pytorch%20with%20Dali/data_processing.py"><code class="language-plaintext highlighter-rouge">data_processing.py</code></a> file.</p>

<ul>
  <li>
<strong>png2numpy</strong> function helps us convert the <em>png</em> format into the <em>npy</em> format and save images and masks in <strong>data_root_npy</strong> folder.</li>
  <li>
<strong>make_csv_file_npy</strong> makes 2 CVS files train.cvs and valid.csv having the previous form and be saved at 
<strong>f”{data_root_npy}/csv_file”</strong> folder.</li>
</ul>

<h2 id="3-nvidia-data-loading-library-dali">
<a class="anchor" href="#3-nvidia-data-loading-library-dali" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. NVIDIA Data Loading Library (DALI)</h2>

<p><code class="language-plaintext highlighter-rouge">DALI</code> is open source library for decoding and augmenting images,videos and speech to accelerate deep learning applications. DALI reduces latency and training time, mitigating bottlenecks, by overlapping training and pre-processing. It provides a drop-in replacement for built in data loaders and data iterators in popular deep learning frameworks for easy integration or retargeting to different frameworks.</p>

<p>Let us discuss the difference between a Naive Deeplearning Pipeline, Kornia Deep Learning Pipeline and DALI Deeplearning Pipeline.</p>

<ul>
  <li>
    <p><strong>Naive Deeplearning Pipeline</strong>: The pre-processing of the data occurs on the CPU, the model will be typically trained on GPU/TPU.</p>
  </li>
  <li>
    <p><strong>Kornia Deep Learning Pipeline</strong>: The reading, resezing or padding data occur on CPU, the transform (augmentation) and model training ran on GPU/TPU. The transform is consider as an <strong>nn.Module</strong>. Then <em>transform</em> is the <strong>nn.Module</strong> object that <em>forward</em> input x of size $B\times C \times H \times W$ and obtain the output of size $B\times C\times H \times W$.</p>
  </li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ModelWithAugumentation</span><span class="p">(</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="s">"""Module to perform data augmentation on torch tensors."""</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">transform_module</span><span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">,</span> <span class="n">model</span> <span class="p">:</span> <span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">transform_module</span> <span class="o">=</span> <span class="n">transform_module</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tensor</span><span class="p">:</span>
        <span class="n">augmented_x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transform_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># BxCxHxW
</span>        <span class="n">x_out</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">model</span><span class="p">(</span><span class="n">augmented_x</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x_out</span>
</code></pre></div></div>

<ul>
  <li>
<strong>DALI Deeplearning Pipeline</strong>: In the reading image, we have two components: encoding and decoding. With DALI library, we can read do encoding by CPUs and decoding by GPUs that work on batch. All other tasks will work on GPUs. We remark that the transform in DALI Pipeline works on data of several types: 
$B\times C \times H \timesW$, $B\times H\times W\timesC$. That is why DALI can easily be retargeted to TensorFlow, PyTorch, and MXNet.</li>
</ul>

<p>The DALI Training Pipeline</p>

<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/do/qg/tu/doqgtugeu1kqtdtojhospmro0j0.jpeg"> -->
<p><img src="https://habrastorage.org/webt/do/qg/tu/doqgtugeu1kqtdtojhospmro0j0.jpeg" alt="" title="DALI Training Pipeline"></p>

<p>DALI Library in the whole Pipieline.</p>

<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/g1/31/ga/g131gag8f-3co1irt5qq8rl5oui.png"> -->

<p><img src="https://habrastorage.org/webt/g1/31/ga/g131gag8f-3co1irt5qq8rl5oui.png" alt="" title="DALI Library in the training pipeline"></p>

<h2 id="4-training-the-segmentation-problem-with-dali-and-pytorch-lighiting">
<a class="anchor" href="#4-training-the-segmentation-problem-with-dali-and-pytorch-lighiting" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Training the Segmentation problem with DALI and Pytorch Lighiting.</h2>

<p>In this part, we will details how to do processing the data in <code class="language-plaintext highlighter-rouge">DALI</code> and train the model by Pytorch Lighiting.</p>

<h3 id="41-define-data-pipeline-by-dali">
<a class="anchor" href="#41-define-data-pipeline-by-dali" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.1 Define Data Pipeline by DALI</h3>

<p>We will define the processing data pipeline by using <code class="language-plaintext highlighter-rouge">dali</code>, instead of using <code class="language-plaintext highlighter-rouge">torch.utils.data</code>.</p>

<p>We first define new class: <code class="language-plaintext highlighter-rouge">GenericPipeline</code> that wraps the <code class="language-plaintext highlighter-rouge">nvidia.dali.pipeline.Pipeline</code> class</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">nvidia.dali.ops</span> <span class="k">as</span> <span class="n">ops</span>
<span class="kn">import</span> <span class="nn">nvidia.dali.types</span> <span class="k">as</span> <span class="n">types</span>
<span class="kn">from</span> <span class="nn">nvidia.dali.pipeline</span> <span class="kn">import</span> <span class="n">Pipeline</span>

<span class="k">class</span> <span class="nc">GenericPipeline</span><span class="p">(</span><span class="n">Pipeline</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">,</span> <span class="n">device_id</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">,</span> <span class="n">device_id</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="n">kwargs</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">dim</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">"dim"</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">device_id</span>
        <span class="c1"># self.patch_size = [384,384]
</span>        <span class="bp">self</span><span class="p">.</span><span class="n">load_to_gpu</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">"load_to_gpu"</span><span class="p">]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">input_x</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_reader</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s">"imgs"</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">input_y</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">get_reader</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s">"lbls"</span><span class="p">])</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">cast</span> <span class="o">=</span> <span class="n">ops</span><span class="p">.</span><span class="n">Cast</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="s">"gpu"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">types</span><span class="p">.</span><span class="n">DALIDataType</span><span class="p">.</span><span class="n">FLOAT</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_reader</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">ops</span><span class="p">.</span><span class="n">readers</span><span class="p">.</span><span class="n">Numpy</span><span class="p">(</span>
            <span class="n">files</span><span class="o">=</span><span class="n">data</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="s">"cpu"</span><span class="p">,</span>
            <span class="n">read_ahead</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">dont_use_mmap</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">pad_last_batch</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">shard_id</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">device</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">kwargs</span><span class="p">[</span><span class="s">"seed"</span><span class="p">],</span>
            <span class="n">num_shards</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">kwargs</span><span class="p">[</span><span class="s">"gpus"</span><span class="p">],</span>
            <span class="n">shuffle_after_epoch</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">kwargs</span><span class="p">[</span><span class="s">"shuffle"</span><span class="p">],</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">load_data</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">input_x</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"ReaderX"</span><span class="p">)</span>  <span class="c1"># read X
</span>        <span class="n">img</span> <span class="o">=</span> <span class="n">img</span><span class="p">.</span><span class="n">gpu</span><span class="p">()</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="k">if</span> <span class="bp">self</span><span class="p">.</span><span class="n">input_y</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
            <span class="n">lbl</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">input_y</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="s">"ReaderY"</span><span class="p">)</span>  <span class="c1"># read Y
</span>            <span class="n">lbl</span> <span class="o">=</span> <span class="n">lbl</span><span class="p">.</span><span class="n">gpu</span><span class="p">()</span>
            <span class="n">lbl</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">lbl</span><span class="p">)</span>

            <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span>
        <span class="k">return</span> <span class="n">img</span>

</code></pre></div></div>

<p>The initial input of GenericPipeline is:</p>
<ul>
  <li>batch_size: batchsize</li>
  <li>num_threads: number of workers</li>
  <li>device_id: gpu device</li>
  <li>kwargs: the dictionary that has the infomations of parameters and train/valid data.</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"dim"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s">"seed"</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
            <span class="s">"gpus"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s">"overlap"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
            <span class="s">"benchmark"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
            <span class="s">"num_workers"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s">"oversampling"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
            <span class="s">"test_batches"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s">"train_batches"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s">"load_to_gpu"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
        <span class="p">}</span>
</code></pre></div></div>

<p>We now can define <code class="language-plaintext highlighter-rouge">ValidPipeline</code> and <code class="language-plaintext highlighter-rouge">TrainPipeline</code> based on the <code class="language-plaintext highlighter-rouge">GenericPipeline</code></p>

<h4 id="validpipeline">
<a class="anchor" href="#validpipeline" aria-hidden="true"><span class="octicon octicon-link"></span></a>ValidPipeline</h4>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">ValidPipeline</span><span class="p">(</span><span class="n">GenericPipeline</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">,</span> <span class="n">device_id</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">,</span> <span class="n">device_id</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="c1"># self.invert_resampled_y = kwargs["invert_resampled_y"]
</span>        <span class="c1"># if self.invert_resampled_y:
</span>        <span class="c1">#     self.input_meta = self.get_reader(kwargs["meta"])
</span>        <span class="c1">#     self.input_orig_y = self.get_reader(kwargs["orig_lbl"])
</span>        <span class="k">print</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">kwargs</span><span class="p">[</span><span class="s">"imgs"</span><span class="p">]))</span>

    <span class="k">def</span> <span class="nf">define_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">resize_fn</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">lbl</span><span class="p">)</span>  <span class="c1"># reszie to inpput size (384)
</span>        <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transpose_fn</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">lbl</span><span class="p">)</span>

        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span>

</code></pre></div></div>
<p>Here, we remark that define_graph is the function to do the data processing. For ValidPipeline, the flow of the data will be:</p>
<ul>
  <li>load_data</li>
  <li>resize data</li>
  <li>transpose data (convert image into the size of CxHxW)</li>
</ul>

<h4 id="trainpipeline">
<a class="anchor" href="#trainpipeline" aria-hidden="true"><span class="octicon octicon-link"></span></a>TrainPipeline</h4>

<p>Similar, we have the TrainPipeline</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TrainPipeline</span><span class="p">(</span><span class="n">GenericPipeline</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">,</span> <span class="n">device_id</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">num_threads</span><span class="p">,</span> <span class="n">device_id</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">oversampling</span> <span class="o">=</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">"oversampling"</span><span class="p">]</span>

    <span class="s">"""
    define some augumentations, for more augumentation, please read </span><span class="se">\
</span><span class="s">        https://github.com/NVIDIA/DALI/tree/main/docs/examples/image_processing
    """</span>

    <span class="o">@</span><span class="nb">staticmethod</span>
    <span class="k">def</span> <span class="nf">slice_fn</span><span class="p">(</span><span class="n">img</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">.</span><span class="nb">slice</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

    <span class="k">def</span> <span class="nf">resize</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">interp_type</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">.</span><span class="n">resize</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">interp_type</span><span class="o">=</span><span class="n">interp_type</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">crop_shape_float</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">noise_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">img_noised</span> <span class="o">=</span> <span class="n">img</span> <span class="o">+</span> <span class="n">fn</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">normal</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">stddev</span><span class="o">=</span><span class="n">fn</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="mf">0.33</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">random_augmentation</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">img_noised</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">blur_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">img_blurred</span> <span class="o">=</span> <span class="n">fn</span><span class="p">.</span><span class="n">gaussian_blur</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">sigma</span><span class="o">=</span><span class="n">fn</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.5</span><span class="p">,</span> <span class="mf">1.5</span><span class="p">)))</span>
        <span class="k">return</span> <span class="n">random_augmentation</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">img_blurred</span><span class="p">,</span> <span class="n">img</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">brightness_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">brightness_scale</span> <span class="o">=</span> <span class="n">random_augmentation</span><span class="p">(</span><span class="mf">0.15</span><span class="p">,</span> <span class="n">fn</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.7</span><span class="p">,</span> <span class="mf">1.3</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span> <span class="o">*</span> <span class="n">brightness_scale</span>

    <span class="k">def</span> <span class="nf">contrast_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">):</span>
        <span class="n">scale</span> <span class="o">=</span> <span class="n">random_augmentation</span><span class="p">(</span><span class="mf">0.13</span><span class="p">,</span> <span class="n">fn</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">uniform</span><span class="p">(</span><span class="nb">range</span><span class="o">=</span><span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">1.1</span><span class="p">)),</span> <span class="mf">1.0</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">math</span><span class="p">.</span><span class="n">clamp</span><span class="p">(</span><span class="n">img</span> <span class="o">*</span> <span class="n">scale</span><span class="p">,</span> <span class="n">fn</span><span class="p">.</span><span class="n">reductions</span><span class="p">.</span><span class="nb">min</span><span class="p">(</span><span class="n">img</span><span class="p">),</span> <span class="n">fn</span><span class="p">.</span><span class="n">reductions</span><span class="p">.</span><span class="nb">max</span><span class="p">(</span><span class="n">img</span><span class="p">))</span>

    <span class="k">def</span> <span class="nf">flips_fn</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span><span class="p">):</span>
        <span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"horizontal"</span><span class="p">:</span> <span class="n">fn</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">coin_flip</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
            <span class="s">"vertical"</span><span class="p">:</span> <span class="n">fn</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">coin_flip</span><span class="p">(</span><span class="n">probability</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="k">return</span> <span class="n">fn</span><span class="p">.</span><span class="n">flip</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">),</span> <span class="n">fn</span><span class="p">.</span><span class="n">flip</span><span class="p">(</span><span class="n">lbl</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">define_graph</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">load_data</span><span class="p">()</span>
        <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">resize_fn</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">lbl</span><span class="p">)</span>  <span class="c1"># reszie to inpput size (384)
</span>        <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">flips_fn</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">lbl</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">noise_fn</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">blur_fn</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">brightness_fn</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>
        <span class="n">img</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">contrast_fn</span><span class="p">(</span><span class="n">img</span><span class="p">)</span>

        <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span> <span class="o">=</span> <span class="bp">self</span><span class="p">.</span><span class="n">transpose_fn</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">lbl</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">lbl</span>

</code></pre></div></div>

<p>For the <code class="language-plaintext highlighter-rouge">TrainPipeline</code>, we need more augmentations. The augmentation is defined in the <code class="language-plaintext highlighter-rouge">define_graph</code> function.</p>

<p>For the augmentation in DALI, we need to redefine all of transform functions. For more infomation, read the <a href="https://github.com/NVIDIA/DALI/tree/main/docs/examples/image_processing">dali tutorial</a>.</p>

<p>For the convenience, we will define the function <code class="language-plaintext highlighter-rouge">fetch_dali_loader</code> that will generate <code class="language-plaintext highlighter-rouge">Pipeline</code> (TrainPipeline, ValidPipeline) depends on the type of dataset.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">fetch_dali_loader</span><span class="p">(</span><span class="n">imgs</span><span class="p">,</span> <span class="n">lbls</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">mode</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="s">"Empty list of images!"</span>
    <span class="k">if</span> <span class="n">lbls</span> <span class="ow">is</span> <span class="ow">not</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">lbls</span><span class="p">),</span> <span class="sa">f</span><span class="s">"Number of images (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">imgs</span><span class="p">)</span><span class="si">}</span><span class="s">) not matching number of labels (</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">lbls</span><span class="p">)</span><span class="si">}</span><span class="s">)"</span>
    <span class="n">pipeline</span> <span class="o">=</span> <span class="n">PIPELINES</span><span class="p">[</span><span class="n">mode</span><span class="p">]</span>
    <span class="n">shuffle</span> <span class="o">=</span> <span class="bp">True</span> <span class="k">if</span> <span class="n">mode</span> <span class="o">==</span> <span class="s">"train"</span> <span class="k">else</span> <span class="bp">False</span>
    <span class="n">load_to_gpu</span> <span class="o">=</span> <span class="bp">True</span> <span class="k">if</span> <span class="n">mode</span> <span class="ow">in</span> <span class="p">[</span><span class="s">"eval"</span><span class="p">,</span> <span class="s">"test"</span><span class="p">]</span> <span class="k">else</span> <span class="bp">False</span>
    <span class="n">pipe_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="s">"imgs"</span><span class="p">:</span> <span class="n">imgs</span><span class="p">,</span> <span class="s">"lbls"</span><span class="p">:</span> <span class="n">lbls</span><span class="p">,</span> <span class="s">"load_to_gpu"</span><span class="p">:</span> <span class="n">load_to_gpu</span><span class="p">,</span> <span class="s">"shuffle"</span><span class="p">:</span> <span class="n">shuffle</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">}</span>

    <span class="n">rank</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">getenv</span><span class="p">(</span><span class="s">"LOCAL_RANK"</span><span class="p">,</span> <span class="s">"0"</span><span class="p">))</span>
    <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">kwargs</span><span class="p">[</span><span class="s">"num_workers"</span><span class="p">],</span> <span class="n">rank</span><span class="p">,</span> <span class="o">**</span><span class="n">pipe_kwargs</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">pipe</span>
</code></pre></div></div>

<p>Once we have the TrainPipeline and ValidPipeline, we can use them for the LightningWrapper to make the lightning data module.</p>

<h3 id="42-lightningwrapper">
<a class="anchor" href="#42-lightningwrapper" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.2 LightningWrapper</h3>

<p>Our LightningDataModule of Nail data is defined by</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">NailSegmentationDaliDali</span><span class="p">(</span><span class="n">LightningDataModule</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">data_root_npy</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">csv_folder</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">()</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">data_root_npy</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">data_root_npy</span><span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">csv_folder</span> <span class="o">=</span> <span class="n">csv_folder</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">train_csv</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">csv_folder</span><span class="p">,</span> <span class="s">"train.csv"</span><span class="p">))</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">valid_csv</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">csv_folder</span><span class="p">,</span> <span class="s">"valid.csv"</span><span class="p">))</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">kwargs</span> <span class="o">=</span> <span class="p">{</span>
            <span class="s">"dim"</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
            <span class="s">"seed"</span><span class="p">:</span> <span class="mi">42</span><span class="p">,</span>
            <span class="s">"gpus"</span><span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
            <span class="s">"overlap"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
            <span class="s">"benchmark"</span><span class="p">:</span> <span class="bp">False</span><span class="p">,</span>
            <span class="s">"num_workers"</span><span class="p">:</span> <span class="mi">4</span><span class="p">,</span>
            <span class="s">"oversampling"</span><span class="p">:</span> <span class="mf">0.4</span><span class="p">,</span>
            <span class="s">"test_batches"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s">"train_batches"</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s">"load_to_gpu"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
        <span class="p">}</span>

    <span class="k">def</span> <span class="nf">prepare_data</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">def</span> <span class="nf">setup</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stage</span><span class="o">=</span><span class="bp">None</span><span class="p">):</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">train_imgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_root_npy</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">train_csv</span><span class="p">[</span><span class="s">"images"</span><span class="p">]]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">train_lbls</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_root_npy</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">train_csv</span><span class="p">[</span><span class="s">"masks"</span><span class="p">]]</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">val_imgs</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_root_npy</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">valid_csv</span><span class="p">[</span><span class="s">"images"</span><span class="p">]]</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">val_lbls</span> <span class="o">=</span> <span class="p">[</span><span class="n">os</span><span class="p">.</span><span class="n">path</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="bp">self</span><span class="p">.</span><span class="n">data_root_npy</span><span class="p">,</span> <span class="n">path</span><span class="p">)</span> <span class="k">for</span> <span class="n">path</span> <span class="ow">in</span> <span class="bp">self</span><span class="p">.</span><span class="n">valid_csv</span><span class="p">[</span><span class="s">"masks"</span><span class="p">]]</span>

        <span class="bp">self</span><span class="p">.</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">fetch_dali_loader</span><span class="p">(</span>
            <span class="n">imgs</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">train_imgs</span><span class="p">,</span> <span class="n">lbls</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">train_lbls</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"train"</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="p">.</span><span class="n">kwargs</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="p">.</span><span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">fetch_dali_loader</span><span class="p">(</span>
            <span class="n">imgs</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">val_imgs</span><span class="p">,</span> <span class="n">lbls</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">val_lbls</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="bp">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s">"eval"</span><span class="p">,</span> <span class="o">**</span><span class="bp">self</span><span class="p">.</span><span class="n">kwargs</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">train_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">output_map</span> <span class="o">=</span> <span class="p">[</span><span class="s">"image"</span><span class="p">,</span> <span class="s">"label"</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">LightningWrapper</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">train_dataset</span><span class="p">,</span>
            <span class="n">auto_reset</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">reader_name</span><span class="o">=</span><span class="s">"ReaderX"</span><span class="p">,</span>
            <span class="n">output_map</span><span class="o">=</span><span class="n">output_map</span><span class="p">,</span>
            <span class="n">dynamic_shape</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">val_dataloader</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">output_map</span> <span class="o">=</span> <span class="p">[</span><span class="s">"image"</span><span class="p">,</span> <span class="s">"label"</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">LightningWrapper</span><span class="p">(</span>
            <span class="bp">self</span><span class="p">.</span><span class="n">valid_dataset</span><span class="p">,</span>
            <span class="n">auto_reset</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
            <span class="n">reader_name</span><span class="o">=</span><span class="s">"ReaderX"</span><span class="p">,</span>
            <span class="n">output_map</span><span class="o">=</span><span class="n">output_map</span><span class="p">,</span>
            <span class="n">dynamic_shape</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
        <span class="p">)</span>

</code></pre></div></div>

<ul>
  <li>Here in the setup function, we use fetch_dali_loader to get the datapipeline for the train and valid stages</li>
  <li>train_dataloader and val_dataloader is defined thank to the <strong>LightningWrapper</strong> class</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">LightningWrapper</span><span class="p">(</span><span class="n">DALIGenericIterator</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">pipe</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">().</span><span class="n">__init__</span><span class="p">(</span><span class="n">pipe</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">__next__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="n">out</span> <span class="o">=</span> <span class="nb">super</span><span class="p">().</span><span class="n">__next__</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
        <span class="k">return</span> <span class="n">out</span>
</code></pre></div></div>

<blockquote>
  <p>Remark: The input of the model will be dicts of keys [“image”, “label”].</p>
</blockquote>

<p>It means</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">input_batch</span> <span class="o">=</span> <span class="p">{</span><span class="s">"image"</span><span class="p">:</span> <span class="n">images</span><span class="p">,</span> <span class="s">"label"</span><span class="p">:</span> <span class="n">masks</span><span class="p">}</span>

</code></pre></div></div>

<p>Then we also need to slight modify the train loop (<code class="language-plaintext highlighter-rouge">training_step</code>) and the valid loop (<code class="language-plaintext highlighter-rouge">validation_step</code>) of the LightningModule.</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def training_step(self, batch, batch_idx):
    imgs, masks = batch["image"].float(), batch["label"]

    logits = self(imgs)
    train_loss = self.loss_function(logits, masks)
    train_dice_soft = self.dice_soft(logits, masks)

    self.log("train_loss", train_loss, prog_bar=True)
    self.log("train_dice_soft", train_dice_soft, prog_bar=True)
    return {"loss": train_loss, "train_dice_soft": train_dice_soft}

</code></pre></div></div>

<p>Once we finish to define <code class="language-plaintext highlighter-rouge">LightningModule</code> and <code class="language-plaintext highlighter-rouge">LightningDataModule</code>, we can jump to the <code class="language-plaintext highlighter-rouge">Trainer</code> to run the training.</p>

<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/qm/q4/jv/qmq4jvmclavtrtfailqkuvm10-8.png"> -->
<p><img src="https://habrastorage.org/webt/qm/q4/jv/qmq4jvmclavtrtfailqkuvm10-8.png" alt="" title="Trainer"></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>
<span class="n">model</span> <span class="o">=</span> <span class="n">SegFormer</span><span class="p">(</span><span class="n">config</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">encoder_name</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">size</span><span class="p">,</span> <span class="n">config</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="n">classes</span><span class="p">)</span>

<span class="n">datamodule</span> <span class="o">=</span> <span class="n">NailSegmentation</span><span class="p">(</span>
    <span class="n">data_root</span><span class="o">=</span><span class="n">data_root</span><span class="p">,</span>
    <span class="n">csv_path</span><span class="o">=</span><span class="n">csv_path</span><span class="p">,</span>
    <span class="n">test_path</span><span class="o">=</span><span class="s">""</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">model_lighning</span> <span class="o">=</span> <span class="n">LitNailSegmentation</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="p">.</span><span class="n">training</span><span class="p">.</span><span class="n">learning_rate</span><span class="p">)</span>


<span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="n">trainer</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model_lighning</span><span class="p">,</span>
    <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span>
<span class="p">)</span>

</code></pre></div></div>

<p><strong>For more details, we can find the full source code at <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/tree/master/Part%205-Pytorch%20with%20Dali">github</a></strong></p>

<h3 id="references">
<a class="anchor" href="#references" aria-hidden="true"><span class="octicon octicon-link"></span></a>References</h3>

<ul>
  <li><a href="https://hphuongdhsp.github.io/ml-blog/2022/08/03/segmentation-model-part3.html">Segmentation Model-Part III - Training deep learning segmentation models in Pytorch Lightning</a></li>
  <li><a href="https://docs.nvidia.com/deeplearning/dali/user-guide/docs/index.html">NVIDIA DALI Documentation</a></li>
  <li><a href="https://github.com/NVIDIA/DALI/blob/main/docs/examples/image_processing/augmentation_gallery.ipynb">Augmentation Gallery</a></li>
  <li><a href="https://github.com/NVIDIA/DeepLearningExamples/tree/master/PyTorch/Segmentation/nnUNet">nnU-Net For PyTorch</a></li>
</ul>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="hphuongdhsp/ml-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/ml-blog/pytorchlightning/semanticsegmentation/deeplearning/dali/2022/08/06/segmentation-model-part5.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ml-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/ml-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/ml-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>share2learn machine learning blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/hphuongdhsp" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/ml-blog/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://www.github.com/hphuongdhsp" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/ml-blog/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
