<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Segmentation Model-Part I - Training deep learning segmentation models in Tensorflow | Hoang Phuong’ Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Segmentation Model-Part I - Training deep learning segmentation models in Tensorflow" />
<meta name="author" content="Nguyen Hoang-Phuong" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The first part of the Segmentation Tutorial Series, a step-by-step guide to developing deep learning segmentation models in TensorFlow" />
<meta property="og:description" content="The first part of the Segmentation Tutorial Series, a step-by-step guide to developing deep learning segmentation models in TensorFlow" />
<link rel="canonical" href="https://hphuongdhsp.github.io/ml-blog/tensorflow/semanticsegmentation/deeplearning/2022/08/02/segmentation-model-part1.html" />
<meta property="og:url" content="https://hphuongdhsp.github.io/ml-blog/tensorflow/semanticsegmentation/deeplearning/2022/08/02/segmentation-model-part1.html" />
<meta property="og:site_name" content="Hoang Phuong’ Blog" />
<meta property="og:image" content="https://hphuongdhsp.github.io/ml-blog/images/tensorflow.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-02T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://hphuongdhsp.github.io/ml-blog/images/tensorflow.png" />
<meta property="twitter:title" content="Segmentation Model-Part I - Training deep learning segmentation models in Tensorflow" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Nguyen Hoang-Phuong"},"dateModified":"2022-08-02T00:00:00-05:00","datePublished":"2022-08-02T00:00:00-05:00","description":"The first part of the Segmentation Tutorial Series, a step-by-step guide to developing deep learning segmentation models in TensorFlow","headline":"Segmentation Model-Part I - Training deep learning segmentation models in Tensorflow","image":"https://hphuongdhsp.github.io/ml-blog/images/tensorflow.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://hphuongdhsp.github.io/ml-blog/tensorflow/semanticsegmentation/deeplearning/2022/08/02/segmentation-model-part1.html"},"url":"https://hphuongdhsp.github.io/ml-blog/tensorflow/semanticsegmentation/deeplearning/2022/08/02/segmentation-model-part1.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ml-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://hphuongdhsp.github.io/ml-blog/feed.xml" title="Hoang Phuong' Blog" /><link rel="shortcut icon" type="image/x-icon" href="/ml-blog/images/hp.ico">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/ml-blog/">Hoang Phuong&#39; Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/ml-blog/about/">About Me</a><a class="page-link" href="/ml-blog/search/">Search</a><a class="page-link" href="/ml-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Segmentation Model-Part I - Training deep learning segmentation models in Tensorflow</h1><p class="page-description">The first part of the Segmentation Tutorial Series, a step-by-step guide to developing deep learning segmentation models in TensorFlow</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-02T00:00:00-05:00" itemprop="datePublished">
        Aug 2, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Nguyen Hoang-Phuong</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      10 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/ml-blog/categories/#tensorflow">tensorflow</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#semanticsegmentation">semanticsegmentation</a>
        &nbsp;
      
        <a class="category-tags-link" href="/ml-blog/categories/#deeplearning">deeplearning</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#1-problem-description-and-dataset">1. Problem Description and Dataset</a></li>
<li class="toc-entry toc-h2"><a href="#2-data-preparation">2. Data Preparation</a></li>
<li class="toc-entry toc-h2"><a href="#3-define-dataloader">3. Define DataLoader</a>
<ul>
<li class="toc-entry toc-h3"><a href="#naive-pipeline">Naive pipeline</a></li>
<li class="toc-entry toc-h3"><a href="#31-get-images-and-masks-from-a-dataframe">3.1 Get images and masks from a dataframe.</a></li>
<li class="toc-entry toc-h3"><a href="#32-decode-images-and-masks">3.2 Decode images and masks</a></li>
<li class="toc-entry toc-h3"><a href="#33-doing-augmentation">3.3 Doing augmentation</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#4-define-the-segmentation-model">4. Define the Segmentation model</a>
<ul>
<li class="toc-entry toc-h2"><a href="#41-model">4.1 Model</a></li>
</ul>
</li>
<li class="toc-entry toc-h1"><a href="#5-model-training">5 Model Training</a>
<ul>
<li class="toc-entry toc-h2"><a href="#51-mixed_precision">5.1 Mixed_precision</a></li>
<li class="toc-entry toc-h2"><a href="#52-using-wanbd-for-logging">5.2 Using Wanbd for logging.</a></li>
<li class="toc-entry toc-h2"><a href="#53-dataloader">5.3 Dataloader</a></li>
<li class="toc-entry toc-h2"><a href="#54-fit-training">5.4 Fit training</a></li>
</ul>
</li>
</ul><p>In this post, we will cover how to train a segmentation model by using the TensorFlow platform</p>

<h2 id="1-problem-description-and-dataset">
<a class="anchor" href="#1-problem-description-and-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Problem Description and Dataset</h2>

<p>We want to cover a nail semantic segmentation problem. For each image, we want to detect the segmentation of the nail in the image.</p>

<table>
  <thead>
    <tr>
      <th style="text-align: center">Images</th>
      <th style="text-align: center">Masks</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td style="text-align: center"><img align="center" width="300" src="https://habrastorage.org/webt/em/og/9v/emog9v4ya7ssllg5dht77_wehqk.png"></td>
      <td style="text-align: center"><img align="center" width="300" src="https://habrastorage.org/webt/hl/bf/ov/hlbfovx1uhrbbebgxndyho9yywo.png"></td>
    </tr>
  </tbody>
</table>

<p>Our data is organized as</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>├── Images
│   ├── 1
│       ├── first_image.png
│       ├── second_image.png
│       ├── third_image.png
│   ├── 2
│   ├── 3
│   ├── 4
├── Masks
│   ├── 1
│       ├── first_image.png
│       ├── second_image.png
│       ├── third_image.png
│   ├── 2
│   ├── 3
│   ├── 4

</code></pre></div></div>

<p>We have two folders: <code class="language-plaintext highlighter-rouge">Images</code> and <code class="language-plaintext highlighter-rouge">Masks</code>,  each folder has four sub-folders <code class="language-plaintext highlighter-rouge">1</code>, <code class="language-plaintext highlighter-rouge">2</code>, <code class="language-plaintext highlighter-rouge">3</code>, <code class="language-plaintext highlighter-rouge">4</code> correspond to four types of distribution of nails. <code class="language-plaintext highlighter-rouge">Images</code> is the data folder and <code class="language-plaintext highlighter-rouge">Masks</code> is the label folder, which is the segmentations of input images.</p>

<p>We download data from <a href="https://drive.google.com/file/d/1qBLwdQeu9nvTw70E46XNXMciB0aKsM7r/view?usp=sharing">link</a> and put it in <code class="language-plaintext highlighter-rouge">data_root</code>, for example</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_root</span> <span class="o">=</span> <span class="s">"./nail-segmentation-dataset"</span>
</code></pre></div></div>

<h2 id="2-data-preparation">
<a class="anchor" href="#2-data-preparation" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Data Preparation</h2>

<p>For the convenience of loading data, we will store data information in a data frame (or CSV file).</p>

<p>We want to have the CSV file that stores the image and mask paths</p>

<table>
  <thead>
    <tr>
      <th>index</th>
      <th>images</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>path_first_image.png</td>
    </tr>
    <tr>
      <td>2</td>
      <td>path_second_image.png</td>
    </tr>
    <tr>
      <td>3</td>
      <td>path_third_image.png</td>
    </tr>
    <tr>
      <td>4</td>
      <td>path_fourth_image.png</td>
    </tr>
  </tbody>
</table>

<p>To do that we use</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
from typing import Any
import pandas as pd

from utils import get_all_items, mkdir

def make_csv_file(data_root) -&gt; None:

    list_images_train_masks = get_all_items(os.path.join(data_root, "train", "masks"))

    list_images_train_images = get_all_items(os.path.join(data_root, "train", "images"))

    list_images_train = [
        i for i in list_images_train_images if i in list_images_train_masks
    ]

    print(len(list_images_train))
    list_images_valid = get_all_items(os.path.join(data_root, "valid", "masks"))

    train_frame = pd.DataFrame(list_images_train, columns=["images"])

    train_frame["train"] = 1
    valid_frame = pd.DataFrame(list_images_valid, columns=["images"])

    valid_frame["train"] = 0
    mkdir(f"{data_root}/csv_file")
    train_frame.to_csv(f"{data_root}/csv_file/train.csv", index=False)
    valid_frame.to_csv(f"{data_root}/csv_file/valid.csv", index=False)
</code></pre></div></div>

<p>Here <code class="language-plaintext highlighter-rouge">get_all_items</code>, <code class="language-plaintext highlighter-rouge">mkdir</code> are two supported functions (defined in <code class="language-plaintext highlighter-rouge">utils.py</code> file) that help us to find all items in a given folder and make a new folder.</p>

<p>Once we have the data frame, we can go to define the dataset.</p>

<h2 id="3-define-dataloader">
<a class="anchor" href="#3-define-dataloader" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Define DataLoader</h2>

<p>In this part we will do the following steps:</p>

<ul>
  <li>Get lists of images and masks</li>
  <li>Define Dataloader with input being a list of images and masks and output being a list of image batchs which are fed into the model. More precisely:
    <ul>
      <li>Decode images and masks (read images and masks)</li>
      <li>Transform data</li>
      <li>Batch the augmented data.</li>
    </ul>
  </li>
</ul>

<p>Before going to the next part, let’s talk about the advantages of using <code class="language-plaintext highlighter-rouge">tf.data</code> for the data loader pipeline.</p>

<p>The main feature of the next part is the data loader. We use the <code class="language-plaintext highlighter-rouge">tensorflow.data</code> (<code class="language-plaintext highlighter-rouge">tf.data</code>) to load the dataset instead of using Sequence Keras (keras.Sequence). In fact, we can also combine <code class="language-plaintext highlighter-rouge">tf.data</code> and <code class="language-plaintext highlighter-rouge">keras.Sequence</code>. This tutorial focuses on how to load data by <code class="language-plaintext highlighter-rouge">tf.data</code>.</p>

<p>Here is the pipeline loader of tf.data:</p>
<ul>
  <li>Read data from a CSV file</li>
  <li>Transfrom (augumentate) the data</li>
  <li>Load data into the model</li>
</ul>

<p><img src="https://habrastorage.org/webt/0g/ec/1p/0gec1pep-rta5ntt7umwq2ybafy.png" alt="" title="tf.data pipeline">
<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/0g/ec/1p/0gec1pep-rta5ntt7umwq2ybafy.png"> --></p>

<p>The advantages of this method are:</p>
<ul>
  <li>Loading data by using multi-processing</li>
  <li>Don’t have the memory leak phenomenal</li>
  <li>Flexible to load dataset, can load weight sample data (using <code class="language-plaintext highlighter-rouge">tf.compat.v1.data.experimental.sample_from_datasets</code> )</li>
  <li>Downtime and waiting around are minimized while processing is maximized through parallel execution; see the following images:</li>
</ul>

<h3 id="naive-pipeline">
<a class="anchor" href="#naive-pipeline" aria-hidden="true"><span class="octicon octicon-link"></span></a>Naive pipeline</h3>

<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/se/pj/bx/sepjbxl-cofjvbatz7x8xp6wn3i.png"> -->
<p><img src="https://habrastorage.org/webt/se/pj/bx/sepjbxl-cofjvbatz7x8xp6wn3i.png" alt="" title="Naive pipeline"></p>

<p>This is the typical workflow of a naive data pipeline, there is always some idle time and overhead due to the inefficiency of sequential execution.</p>

<p>In contrast, consider: <code class="language-plaintext highlighter-rouge">tf.data</code> pipeline</p>

<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/yt/5z/bv/yt5zbvzi3pqdc4l_8ez1c6lzgug.png"> -->
<p><img src="https://habrastorage.org/webt/yt/5z/bv/yt5zbvzi3pqdc4l_8ez1c6lzgug.png" alt="" title="tf.data pipeline"></p>
<h3 id="31-get-images-and-masks-from-a-dataframe">
<a class="anchor" href="#31-get-images-and-masks-from-a-dataframe" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1 Get images and masks from a dataframe.</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_data_path</span><span class="p">(</span><span class="n">data_root</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">],</span> <span class="n">csv_dir</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Path</span><span class="p">],</span> <span class="n">train</span><span class="p">:</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">:</span>

    <span class="n">csv_file</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_csv</span><span class="p">(</span><span class="n">csv_dir</span><span class="p">)</span>
    <span class="n">ids</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">csv_file</span><span class="p">[</span><span class="s">"images"</span><span class="p">])</span>
    <span class="n">images</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_root</span> <span class="o">+</span> <span class="sa">f</span><span class="s">"/</span><span class="si">{</span><span class="n">train</span><span class="si">}</span><span class="s">/images"</span> <span class="o">+</span> <span class="n">fname</span> <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">]</span>
    <span class="n">masks</span> <span class="o">=</span> <span class="p">[</span><span class="n">data_root</span> <span class="o">+</span> <span class="sa">f</span><span class="s">"/</span><span class="si">{</span><span class="n">train</span><span class="si">}</span><span class="s">/masks"</span> <span class="o">+</span> <span class="n">fname</span> <span class="k">for</span> <span class="n">fname</span> <span class="ow">in</span> <span class="n">ids</span><span class="p">]</span>
    <span class="k">return</span> <span class="p">(</span><span class="n">images</span><span class="p">,</span> <span class="n">masks</span><span class="p">)</span>
</code></pre></div></div>

<h3 id="32-decode-images-and-masks">
<a class="anchor" href="#32-decode-images-and-masks" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2 Decode images and masks</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">load_image_and_mask_from_path</span><span class="p">(</span><span class="n">image_path</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">string</span><span class="p">,</span> <span class="n">mask_path</span><span class="p">:</span> <span class="n">tf</span><span class="p">.</span><span class="n">string</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="s">"""this function is to load image and mask

    Args:
        image_path (tf.string): the tensorflow string of image
        mask_path (tf.string): the tensorflow string of mask

    Returns:
        [type]: image and mask
    """</span>
    <span class="c1"># read image by tensorflow function
</span>    <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">image_path</span><span class="p">)</span>
    <span class="n">img</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">decode_image</span><span class="p">(</span><span class="n">img</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
    <span class="c1"># read mask by tensorflow function
</span>    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">io</span><span class="p">.</span><span class="n">read_file</span><span class="p">(</span><span class="n">mask_path</span><span class="p">)</span>
    <span class="n">mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">image</span><span class="p">.</span><span class="n">decode_image</span><span class="p">(</span><span class="n">mask</span><span class="p">,</span> <span class="n">channels</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">img</span><span class="p">,</span> <span class="n">mask</span>
</code></pre></div></div>

<h3 id="33-doing-augmentation">
<a class="anchor" href="#33-doing-augmentation" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.3 Doing augmentation</h3>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code>    <span class="k">def</span> <span class="nf">aug_fn</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="c1"># do augumentation by albumentations library
</span>        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s">"image"</span><span class="p">:</span> <span class="n">image</span><span class="p">,</span> <span class="s">"mask"</span><span class="p">:</span> <span class="n">mask</span><span class="p">}</span>
        <span class="n">aug_data</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">)</span>
        <span class="n">aug_img</span> <span class="o">=</span> <span class="n">aug_data</span><span class="p">[</span><span class="s">"image"</span><span class="p">]</span>
        <span class="n">aug_mask</span> <span class="o">=</span> <span class="n">aug_data</span><span class="p">[</span><span class="s">"mask"</span><span class="p">]</span>
        <span class="c1"># do normalize by using the tensorflow.cast function
</span>        <span class="n">aug_img</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">aug_img</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="n">aug_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">aug_mask</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">aug_img</span><span class="p">,</span> <span class="n">aug_mask</span>
</code></pre></div></div>

<p>Here we use <a href="https://albumentations.ai/">Albumentations</a> library to define the transform. <strong>Albumentations</strong> is a Python library for fast and flexible image augmentations. Albumentations efficiently implements a rich variety of image transform operations that are optimized for performance and does so while providing a concise yet powerful image augmentation interface for different computer vision tasks, including object classification, segmentation, and detection. For example, we define our validation transform as</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">albumentations</span> <span class="k">as</span> <span class="n">A</span>

<span class="k">def</span> <span class="nf">valid_transform</span><span class="p">():</span>
    <span class="k">return</span> <span class="n">A</span><span class="p">.</span><span class="n">Compose</span><span class="p">(</span>
        <span class="p">[</span>
            <span class="n">A</span><span class="p">.</span><span class="n">Resize</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="n">always_apply</span><span class="o">=</span><span class="bp">True</span><span class="p">),</span>
        <span class="p">],</span>
        <span class="n">p</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
</code></pre></div></div>

<p>You can find the detail of transforms in <code class="language-plaintext highlighter-rouge">transform.py</code> file, in the source code given at the post’s end. We remark that, after doing augmentation, we cast the output of transform into TensorFlow type <code class="language-plaintext highlighter-rouge">tensorflow type</code></p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>aug_img = tf.cast(aug_img / 255.0, dtype)
aug_mask = tf.cast(aug_mask / 255.0, dtype)
</code></pre></div></div>

<p>Once we finish the augmentation task, we can do batching of the data by</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
</code></pre></div></div>

<p>Here, the dataset is now an object of <code class="language-plaintext highlighter-rouge">tf.data</code>.</p>

<p>Compose four previous steps, we have the data loader function:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">tf_dataset</span><span class="p">(</span>
    <span class="n">dataset</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">],</span> <span class="n">List</span><span class="p">[</span><span class="nb">str</span><span class="p">]],</span>
    <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">transforms</span><span class="p">:</span> <span class="n">A</span><span class="p">.</span><span class="n">Compose</span><span class="p">,</span>
    <span class="n">dtype</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">],</span>
<span class="p">):</span>
    <span class="sa">r</span><span class="s">"""This function is to create dataloader for tensorflow training

    Args:
        dataset Tuple[List[str], List[str]]: Tuple of List data path that have same size
        shuffle (bool): True if you want shuffle dataset when do training
        batch_size [Any]: None if you dont want spit dataset by batch
        transforms (A.Compose): the augumentation that you want to apple for the data

    Returns:
        datast : the prepare dataset for the training step
    """</span>

    <span class="c1"># do augumentation by albumentations, remark that in the the end, we use tf.cast to normalize
</span>    <span class="c1"># image and mask and also make sure that the output of this function be in form of tensorflow (tf)
</span>    <span class="k">def</span> <span class="nf">aug_fn</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="c1"># do augumentation by albumentations library
</span>        <span class="n">data</span> <span class="o">=</span> <span class="p">{</span><span class="s">"image"</span><span class="p">:</span> <span class="n">image</span><span class="p">,</span> <span class="s">"mask"</span><span class="p">:</span> <span class="n">mask</span><span class="p">}</span>
        <span class="n">aug_data</span> <span class="o">=</span> <span class="n">transforms</span><span class="p">(</span><span class="o">**</span><span class="n">data</span><span class="p">)</span>
        <span class="n">aug_img</span> <span class="o">=</span> <span class="n">aug_data</span><span class="p">[</span><span class="s">"image"</span><span class="p">]</span>
        <span class="n">aug_mask</span> <span class="o">=</span> <span class="n">aug_data</span><span class="p">[</span><span class="s">"mask"</span><span class="p">]</span>
        <span class="c1"># do normalize by using the tensorflow.cast function
</span>        <span class="n">aug_img</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">aug_img</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="n">aug_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">cast</span><span class="p">(</span><span class="n">aug_mask</span> <span class="o">/</span> <span class="mf">255.0</span><span class="p">,</span> <span class="n">dtype</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">aug_img</span><span class="p">,</span> <span class="n">aug_mask</span>

    <span class="k">def</span> <span class="nf">process_data</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
        <span class="c1"># using tf.numpy_function to apply the aug_img to image and mask
</span>        <span class="n">aug_img</span><span class="p">,</span> <span class="n">aug_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">numpy_function</span><span class="p">(</span><span class="n">aug_fn</span><span class="p">,</span> <span class="p">[</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">],</span> <span class="p">[</span><span class="n">dtype</span><span class="p">,</span> <span class="n">dtype</span><span class="p">])</span>
        <span class="k">return</span> <span class="n">aug_img</span><span class="p">,</span> <span class="n">aug_mask</span>

    <span class="c1"># convert the tuple of list (images, masks) into the tensorflow.data form
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">.</span><span class="n">from_tensor_slices</span><span class="p">(</span><span class="n">dataset</span><span class="p">)</span>

    <span class="c1"># apply the map reading image and mask (make sure that the input and output are in the tensorflow form (tf.))
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span><span class="n">load_image_and_mask_from_path</span><span class="p">,</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">multiprocessing</span><span class="p">.</span><span class="n">cpu_count</span><span class="p">()</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">device</span><span class="p">))</span>
    <span class="c1"># shuffle data
</span>    <span class="k">if</span> <span class="n">shuffle</span><span class="p">:</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">shuffle</span><span class="p">(</span><span class="n">buffer_size</span><span class="o">=</span><span class="mi">100000</span><span class="p">)</span>
    <span class="c1"># do the process_data map (augumentation and normalization)
</span>    <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="nb">map</span><span class="p">(</span>
        <span class="n">partial</span><span class="p">(</span><span class="n">process_data</span><span class="p">),</span> <span class="n">num_parallel_calls</span><span class="o">=</span><span class="n">multiprocessing</span><span class="p">.</span><span class="n">cpu_count</span><span class="p">()</span> <span class="o">//</span> <span class="nb">len</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="p">).</span><span class="n">prefetch</span><span class="p">(</span><span class="n">AUTOTUNE</span><span class="p">)</span>
    <span class="c1"># make batchsize, here we use batch_size as a parameter, in some case we dont split dataset by batchsize
</span>    <span class="c1"># for example, if we want to mix multi-dataset, then we skip this step and split dataset by batch_size later
</span>    <span class="k">if</span> <span class="n">batch_size</span><span class="p">:</span>
        <span class="n">dataset</span> <span class="o">=</span> <span class="n">dataset</span><span class="p">.</span><span class="n">batch</span><span class="p">(</span><span class="n">batch_size</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">dataset</span>
</code></pre></div></div>

<h1 id="4-define-the-segmentation-model">
<a class="anchor" href="#4-define-the-segmentation-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Define the Segmentation model</h1>

<p>In this part, we will define the segmentation model by using <code class="language-plaintext highlighter-rouge">segmentation_models</code> library, we also define the loss function, optimization, and metrics.</p>

<p><strong>Segmentation models</strong> is a python library with Neural Networks for Image Segmentation based on Keras (Tensorflow) framework. This is the high-level API, you need only some lines of code to create a Segmentation Neural Network.</p>

<h2 id="41-model">
<a class="anchor" href="#41-model" aria-hidden="true"><span class="octicon octicon-link"></span></a>4.1 Model</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">create_model</span><span class="p">():</span>

    <span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">Unet</span><span class="p">(</span>
        <span class="s">"efficientnetb4"</span><span class="p">,</span>
        <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
        <span class="n">encoder_weights</span><span class="o">=</span><span class="s">"imagenet"</span><span class="p">,</span>
        <span class="n">classes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="c1"># TO USE mixed_precision, HERE WE USE SMALL TRICK, REMOVE THE LAST LAYER AND ADD
</span>    <span class="c1"># THE ACTIVATION SIGMOID WITH THE DTYPE  TF.FLOAT32
</span>    <span class="n">last_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s">"sigmoid"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)(</span><span class="n">model</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">].</span><span class="n">output</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">Model</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="nb">input</span><span class="p">,</span> <span class="n">last_layer</span><span class="p">)</span>

    <span class="c1"># define optimization, here we use the tensorflow addon, but use can also use some normal \
</span>    <span class="c1"># optimazation that is defined in tensorflow.optimizers
</span>    <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tfa</span><span class="p">.</span><span class="n">optimizers</span><span class="p">.</span><span class="n">RectifiedAdam</span><span class="p">()</span>

    <span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">mixed_precision</span><span class="p">:</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">mixed_precision</span><span class="p">.</span><span class="n">LossScaleOptimizer</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">dynamic</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
    <span class="c1"># define a loss fucntion
</span>    <span class="n">dice_loss</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">DiceLoss</span><span class="p">()</span>
    <span class="n">focal_loss</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">losses</span><span class="p">.</span><span class="n">BinaryFocalLoss</span><span class="p">()</span>
    <span class="n">total_loss</span> <span class="o">=</span> <span class="n">dice_loss</span> <span class="o">+</span> <span class="n">focal_loss</span>
    <span class="c1"># define metric
</span>    <span class="n">metrics</span> <span class="o">=</span> <span class="p">[</span>
        <span class="n">sm</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">IOUScore</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
        <span class="n">sm</span><span class="p">.</span><span class="n">metrics</span><span class="p">.</span><span class="n">FScore</span><span class="p">(</span><span class="n">threshold</span><span class="o">=</span><span class="mf">0.5</span><span class="p">),</span>
    <span class="p">]</span>
    <span class="c1"># compile model with optimizer, losses and metrics
</span>    <span class="n">model</span><span class="p">.</span><span class="nb">compile</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">total_loss</span><span class="p">,</span> <span class="n">metrics</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">model</span>

</code></pre></div></div>

<p>Here we use:</p>
<ul>
  <li>The <a href="https://en.wikipedia.org/wiki/U-Net">Unet</a> model with the backbone is <a href="https://paperswithcode.com/method/efficientnet#:~:text=EfficientNet%20is%20a%20convolutional%20neural,resolution%20using%20a%20compound%20coefficient.">efficientnetb4</a>
</li>
  <li>The loss function is the sum <a href="https://en.wikipedia.org/wiki/S%C3%B8rensen%E2%80%93Dice_coefficient"><code class="language-plaintext highlighter-rouge">DiceLoss</code></a> and <a href="https://paperswithcode.com/method/focal-loss#:~:text=Focal%20loss%20applies%20a%20modulating,in%20the%20correct%20class%20increases."><code class="language-plaintext highlighter-rouge">FocalLoss</code></a>
</li>
  <li>The metric is IOU score and FSscore</li>
  <li>The optimization algorithm is <a href="https://ml-explained.com/blog/radam-explained"><code class="language-plaintext highlighter-rouge">RectifiedAdam</code></a>
</li>
</ul>

<h1 id="5-model-training">
<a class="anchor" href="#5-model-training" aria-hidden="true"><span class="octicon octicon-link"></span></a>5 Model Training</h1>

<p>Once we have: dataloader and model we then combine them to run the model. In this part we will introduce some tools that help us boost the efficiency of training:</p>

<ul>
  <li>mixed_precision</li>
  <li>using wanbd as a callback</li>
</ul>

<h2 id="51-mixed_precision">
<a class="anchor" href="#51-mixed_precision" aria-hidden="true"><span class="octicon octicon-link"></span></a>5.1 Mixed_precision</h2>

<p>How does mixed precision work?</p>

<p>Mixed precision training is the use of lower-precision operations (float16 and bfloat16) in a model during training to make it run faster and use less memory. Using mixed precision can improve performance by more than 3 times on modern GPUs and 60% on TPUs.</p>

<p>Here is the mixed precision training flow:</p>

<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/3y/pg/ew/3ypgewgss1uoezkydzapcg0pjgy.png"> -->
<p><img src="https://habrastorage.org/webt/3y/pg/ew/3ypgewgss1uoezkydzapcg0pjgy.png" alt="" title="mixed precision training flow"></p>

<ul>
  <li>We first feed the data as the float16 or bloat16 type, then the input of the model has the low type (float16 and bfloat16).</li>
  <li>All of the calculations in the model are computed with the lower-precision operations.</li>
  <li>Convert the output of the model into float32 to do optimization tasks.</li>
  <li>Update weights, convert them into lower-precision, and continue the next round of training.</li>
</ul>

<p>To train the model in TensorFlow with mixed precision, we just modify:</p>

<ul>
  <li>We first define the global policy:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">if</span> <span class="n">args</span><span class="p">.</span><span class="n">mixed_precision</span><span class="p">:</span>
    <span class="n">policy</span> <span class="o">=</span> <span class="n">mixed_precision</span><span class="p">.</span><span class="n">Policy</span><span class="p">(</span><span class="s">"mixed_float16"</span><span class="p">)</span>
    <span class="n">mixed_precision</span><span class="p">.</span><span class="n">set_policy</span><span class="p">(</span><span class="n">policy</span><span class="p">)</span>
    <span class="k">print</span><span class="p">(</span><span class="s">"Mixed precision enabled"</span><span class="p">)</span>
</code></pre></div></div>

<ul>
  <li>Change the type of output data (the input of model) into <code class="language-plaintext highlighter-rouge">tf.float16</code>:</li>
</ul>

<p>When we load dataset, before suffling and batching we convert the output data into float16. To do that,</p>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">process_data</span><span class="p">(</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">):</span>
    <span class="c1"># using tf.numpy_function to apply the aug_img to image and mask
</span>    <span class="n">aug_img</span><span class="p">,</span> <span class="n">aug_mask</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">numpy_function</span><span class="p">(</span><span class="n">aug_fn</span><span class="p">,</span> <span class="p">[</span><span class="n">image</span><span class="p">,</span> <span class="n">mask</span><span class="p">],</span> <span class="p">[</span><span class="n">dtype</span><span class="p">,</span> <span class="n">dtype</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">aug_img</span><span class="p">,</span> <span class="n">aug_mask</span>
</code></pre></div></div>

<ul>
  <li>Fix the last layer of the model. Here we remark that the dtype of the last layer should be <code class="language-plaintext highlighter-rouge">float32</code>. To do that, in the model part, we add some tricks:</li>
</ul>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">model</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">Unet</span><span class="p">(</span>
    <span class="s">"efficientnetb4"</span><span class="p">,</span>
    <span class="n">input_shape</span><span class="o">=</span><span class="p">(</span><span class="mi">384</span><span class="p">,</span> <span class="mi">384</span><span class="p">,</span> <span class="mi">3</span><span class="p">),</span>
    <span class="n">encoder_weights</span><span class="o">=</span><span class="s">"imagenet"</span><span class="p">,</span>
    <span class="n">classes</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># TO USE mixed_precision, HERE WE USE SMALL TRICK, REMOVE THE LAST LAYER AND ADD
# THE ACTIVATION SIGMOID WITH THE DTYPE  TF.FLOAT32
</span><span class="n">last_layer</span> <span class="o">=</span> <span class="n">tf</span><span class="p">.</span><span class="n">keras</span><span class="p">.</span><span class="n">layers</span><span class="p">.</span><span class="n">Activation</span><span class="p">(</span><span class="n">activation</span><span class="o">=</span><span class="s">"sigmoid"</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">tf</span><span class="p">.</span><span class="n">float32</span><span class="p">)(</span>
    <span class="n">model</span><span class="p">.</span><span class="n">layers</span><span class="p">[</span><span class="o">-</span><span class="mi">2</span><span class="p">].</span><span class="n">output</span>
<span class="p">)</span>
</code></pre></div></div>

<h2 id="52-using-wanbd-for-logging">
<a class="anchor" href="#52-using-wanbd-for-logging" aria-hidden="true"><span class="octicon octicon-link"></span></a>5.2 Using Wanbd for logging.</h2>

<p>In this part, we will cover how to use <code class="language-plaintext highlighter-rouge">wandb</code> for logging. <code class="language-plaintext highlighter-rouge">WandB</code> is a central dashboard to keep track of your hyperparameters, system metrics, and predictions so you can compare models live and share your findings. To do that we use callback of model training as the <code class="language-plaintext highlighter-rouge">WandbLogging</code></p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">wandb</span>
<span class="kn">from</span> <span class="nn">wandb.keras</span> <span class="kn">import</span> <span class="n">WandbCallback</span>
<span class="n">logdir</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">work_dir</span><span class="si">}</span><span class="s">/tensorflow/logs/wandb"</span>
<span class="n">mkdir</span><span class="p">(</span><span class="n">logdir</span><span class="p">)</span>
<span class="n">wandb</span><span class="p">.</span><span class="n">init</span><span class="p">(</span><span class="n">project</span><span class="o">=</span><span class="s">"Segmentation by Tensorflow"</span><span class="p">,</span> <span class="nb">dir</span><span class="o">=</span><span class="n">logdir</span><span class="p">)</span>

<span class="n">wandb</span><span class="p">.</span><span class="n">config</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s">"learning_rate"</span><span class="p">:</span> <span class="n">earning_rate</span><span class="p">,</span>
    <span class="s">"epochs"</span><span class="p">:</span> <span class="n">epochs</span><span class="p">,</span>
    <span class="s">"batch_size"</span><span class="p">:</span> <span class="n">batch_size</span><span class="p">,</span>
<span class="p">}</span>
<span class="n">callbacks</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">WandbCallback</span><span class="p">())</span>

</code></pre></div></div>

<p>We finish the training task by calling the train loader and valid loader and fitting the model. Then</p>

<h2 id="53-dataloader">
<a class="anchor" href="#53-dataloader" aria-hidden="true"><span class="octicon octicon-link"></span></a>5.3 Dataloader</h2>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">data_root</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">args</span><span class="p">.</span><span class="n">data_root</span><span class="p">)</span>
<span class="n">train_csv_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">data_root</span><span class="si">}</span><span class="s">/csv_file/train.csv"</span>
<span class="n">valid_csv_dir</span> <span class="o">=</span> <span class="sa">f</span><span class="s">"</span><span class="si">{</span><span class="n">data_root</span><span class="si">}</span><span class="s">/csv_file/valid.csv"</span>
<span class="c1"># set batch_size
</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">batch_size</span>
<span class="n">epochs</span> <span class="o">=</span> <span class="n">args</span><span class="p">.</span><span class="n">epochs</span>

<span class="c1"># get training and validation set
</span><span class="n">train_dataset</span> <span class="o">=</span> <span class="n">load_data_path</span><span class="p">(</span><span class="n">data_root</span><span class="p">,</span> <span class="n">train_csv_dir</span><span class="p">,</span> <span class="s">"train"</span><span class="p">)</span>
<span class="n">train_loader</span> <span class="o">=</span> <span class="n">tf_dataset</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">train_dataset</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">transforms</span><span class="o">=</span><span class="n">train_transform</span><span class="p">(),</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">device</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">valid_dataset</span> <span class="o">=</span> <span class="n">load_data_path</span><span class="p">(</span><span class="n">data_root</span><span class="p">,</span> <span class="n">valid_csv_dir</span><span class="p">,</span> <span class="s">"valid"</span><span class="p">)</span>
<span class="n">valid_loader</span> <span class="o">=</span> <span class="n">tf_dataset</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">valid_dataset</span><span class="p">,</span>
    <span class="n">shuffle</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">transforms</span><span class="o">=</span><span class="n">valid_transform</span><span class="p">(),</span>
    <span class="n">dtype</span><span class="o">=</span><span class="n">dtype</span><span class="p">,</span>
    <span class="n">device</span><span class="o">=</span><span class="n">args</span><span class="p">.</span><span class="n">device</span><span class="p">,</span>
<span class="p">)</span>

</code></pre></div></div>

<h2 id="54-fit-training">
<a class="anchor" href="#54-fit-training" aria-hidden="true"><span class="octicon octicon-link"></span></a>5.4 Fit training</h2>
<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">train_loader</span><span class="p">,</span>
    <span class="n">steps_per_epoch</span><span class="o">=</span><span class="n">total_steps</span><span class="p">,</span>
    <span class="n">epochs</span><span class="o">=</span><span class="n">epochs</span><span class="p">,</span>
    <span class="n">validation_data</span><span class="o">=</span><span class="n">valid_loader</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
<span class="p">)</span>
</code></pre></div></div>

<p><strong>For more details, we can find the source code at <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/tree/master/Part%201-Tensorflow">github</a></strong></p>

  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="hphuongdhsp/ml-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/ml-blog/tensorflow/semanticsegmentation/deeplearning/2022/08/02/segmentation-model-part1.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ml-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/ml-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/ml-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>share2learn machine learning blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li>
  <a rel="me" href="https://twitter.com/hphuongdhsp" target="_blank" title="twitter">
    <svg class="svg-icon grey">
      <use xlink:href="/ml-blog/assets/minima-social-icons.svg#twitter"></use>
    </svg>
  </a>
</li>
<li>
  <a rel="me" href="https://www.github.com/hphuongdhsp" target="_blank" title="github">
    <svg class="svg-icon grey">
      <use xlink:href="/ml-blog/assets/minima-social-icons.svg#github"></use>
    </svg>
  </a>
</li>
</ul>
</div>

  </div>

</footer>
</body>

</html>
