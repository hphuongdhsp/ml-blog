<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Segmentation Model-Part VI - Training the Segformer model by using Pytorch Lightning and HuggingFace | Hoang Phuong’ Blog</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Segmentation Model-Part VI - Training the Segformer model by using Pytorch Lightning and HuggingFace" />
<meta name="author" content="Nguyen Hoang-Phuong" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The sixth part of the Segmentation Tutorial Series, a guide to developing the SerFormer model for segmentation problem." />
<meta property="og:description" content="The sixth part of the Segmentation Tutorial Series, a guide to developing the SerFormer model for segmentation problem." />
<link rel="canonical" href="https://hphuongdhsp.github.io/ml-blog/2022/08/07/segmentation-model-part6.html" />
<meta property="og:url" content="https://hphuongdhsp.github.io/ml-blog/2022/08/07/segmentation-model-part6.html" />
<meta property="og:site_name" content="Hoang Phuong’ Blog" />
<meta property="og:image" content="https://hphuongdhsp.github.io/ml-blog/images/segformer_architecture.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-08-07T00:00:00-05:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://hphuongdhsp.github.io/ml-blog/images/segformer_architecture.png" />
<meta property="twitter:title" content="Segmentation Model-Part VI - Training the Segformer model by using Pytorch Lightning and HuggingFace" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"Nguyen Hoang-Phuong"},"dateModified":"2022-08-07T00:00:00-05:00","datePublished":"2022-08-07T00:00:00-05:00","description":"The sixth part of the Segmentation Tutorial Series, a guide to developing the SerFormer model for segmentation problem.","headline":"Segmentation Model-Part VI - Training the Segformer model by using Pytorch Lightning and HuggingFace","image":"https://hphuongdhsp.github.io/ml-blog/images/segformer_architecture.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://hphuongdhsp.github.io/ml-blog/2022/08/07/segmentation-model-part6.html"},"url":"https://hphuongdhsp.github.io/ml-blog/2022/08/07/segmentation-model-part6.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/ml-blog/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://hphuongdhsp.github.io/ml-blog/feed.xml" title="Hoang Phuong' Blog" /><link rel="shortcut icon" type="image/x-icon" href="/ml-blog/images/hp.ico">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/ml-blog/">Hoang Phuong&#39; Blog</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/ml-blog/about/">About Me</a><a class="page-link" href="/ml-blog/search/">Search</a><a class="page-link" href="/ml-blog/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Segmentation Model-Part VI -  Training the Segformer model by using Pytorch Lightning and HuggingFace</h1><p class="page-description">The sixth part of the Segmentation Tutorial Series, a guide to developing the SerFormer model for segmentation problem.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2022-08-07T00:00:00-05:00" itemprop="datePublished">
        Aug 7, 2022
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Nguyen Hoang-Phuong</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      6 min read
    
</span></p>

    

    
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul id="toc" class="section-nav">
<li class="toc-entry toc-h2"><a href="#2.-Data-Preparation">2. Data Preparation </a></li>
<li class="toc-entry toc-h2"><a href="#3.-The-Segformer-Model-for-the-semanctic-segmentation-problem">3. The Segformer Model for the semanctic segmentation problem </a>
<ul>
<li class="toc-entry toc-h3"><a href="#3.1-Encoder">3.1 Encoder </a></li>
<li class="toc-entry toc-h3"><a href="#3.2-Decoder">3.2 Decoder </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#4.-Traing-the-Segformer-model-with-Pytorch-Lightning-and-HuggingFace.">4. Traing the Segformer model with Pytorch Lightning and HuggingFace. </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2022-08-07-segmentation-model-part6.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This post is a demonstration of using the Segformer model in HuggingFace. We will focus on:</p>
<ul>
<li>Architecture of the Segformer model</li>
<li>Traing the Segformer model by using Pytorch Lightning and HuggingFace.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Similar to the previous post, we will work with the Segmentation Problem (Nail Segmentation). In the first and second parts we will recall <strong>Problem Description and Dataset</strong>. If you have followed previous posts, you can skip those parts. In the third part, we will focus on the advantages of the Segformer model. The last part of the post will cover the training the Segformer model.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We want to cover a nail semantic segmentation problem. For each image, we want to detect the segmentation of the nail in the image.</p>
<table>
<thead>
<tr>
<th style="text-align:center">Images</th>
<th style="text-align:center">Masks</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img align="center" width="300" src="https://habrastorage.org/webt/em/og/9v/emog9v4ya7ssllg5dht77_wehqk.png"></td>
<td style="text-align:center"><img align="center" width="300" src="https://habrastorage.org/webt/hl/bf/ov/hlbfovx1uhrbbebgxndyho9yywo.png"></td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Our data is organized as</p>
<div class="highlight"><pre><span></span>├── Images
│   ├── <span class="m">1</span>
│       ├── first_image.png
│       ├── second_image.png
│       ├── third_image.png
│   ├── <span class="m">2</span>
│   ├── <span class="m">3</span>
│   ├── <span class="m">4</span>
├── Masks
│   ├── <span class="m">1</span>
│       ├── first_image.png
│       ├── second_image.png
│       ├── third_image.png
│   ├── <span class="m">2</span>
│   ├── <span class="m">3</span>
│   ├── <span class="m">4</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have two folders: <code>Images</code> and <code>Masks</code>. <code>Images</code> is the data folder, and <code>Masks</code> is the label folder, which is the segmentations of input images. Each folder has four sub-folder:  <code>1</code>, <code>2</code>, <code>3</code>, and <code>4</code>, corresponding to four types of nail distribution.</p>
<p>We download data from <a href="https://drive.google.com/file/d/1qBLwdQeu9nvTw70E46XNXMciB0aKsM7r/view?usp=sharing">link</a> and put it in <code>data_root</code>, for example</p>
<div class="highlight"><pre><span></span><span class="n">data_root</span> <span class="o">=</span> <span class="s2">"./nail-segmentation-dataset"</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="2.-Data-Preparation">
<a class="anchor" href="#2.-Data-Preparation" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Data Preparation<a class="anchor-link" href="#2.-Data-Preparation"> </a>
</h2>
<p>Similar to the training pipeline of the previous post, we first make the data frame to store images and masks infos.</p>
<table>
<thead>
<tr>
<th>index</th>
<th>images</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>path_first_image.png</td>
</tr>
<tr>
<td>2</td>
<td>path_second_image.png</td>
</tr>
<tr>
<td>3</td>
<td>path_third_image.png</td>
</tr>
<tr>
<td>4</td>
<td>path_fourth_image.png</td>
</tr>
</tbody>
</table>
<p>For that we use <code>make_csv_file</code> function in <code>data_processing.py</code> file.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="3.-The-Segformer-Model-for-the-semanctic-segmentation-problem">
<a class="anchor" href="#3.-The-Segformer-Model-for-the-semanctic-segmentation-problem" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. The Segformer Model for the semanctic segmentation problem<a class="anchor-link" href="#3.-The-Segformer-Model-for-the-semanctic-segmentation-problem"> </a>
</h2>
<p>The SegFormer model was proposed in SegFormer: <a href="https://arxiv.org/pdf/2105.15203v1.pdf">Simple and Efficient Design for Semantic Segmentation with Transformers</a> by Enze Xie, Wenhai Wang, Zhiding Yu, Anima Anandkumar, Jose M. Alvarez, Ping Luo. The model consists of a hierarchical Transformer encoder and a lightweight all-MLP decode head to achieve great results on image segmentation benchmarks.</p>
<p>The figure below illustrates the architecture of SegFormer</p>
<p><img src="https://habrastorage.org/webt/rj/pf/lv/rjpflvzjcjdeh7vxnls2lzzfl38.png" alt="" title="The architecture of SegFormer"></p>
<!-- <img align="center" width="600"  src="https://habrastorage.org/webt/rj/pf/lv/rjpflvzjcjdeh7vxnls2lzzfl38.png"> -->

<p>SegFormer has the following notable points:</p>
<ul>
<li>The new Transformer encoder (backbone): Mix Transformer (MiT) that extracts coarse and fine features</li>
<li>The decoder is a MLP network to directly fuse the multi-level
features of the encoder part and predicts the semantic segmentation mask</li>
</ul>
<h3 id="3.1-Encoder">
<a class="anchor" href="#3.1-Encoder" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.1 Encoder<a class="anchor-link" href="#3.1-Encoder"> </a>
</h3>
<p>The encoder of SegFormer is a Mix Transformer(MiT). There are six versions of encoders: MiT-B0 to MiT-B5. They have the same architecture, but different sizes. MiT-B0 is our lightweight model for fast inference, while MiT-B5 is the largest model for the best performance. The design of MiT is similar to the Vison Transformer, but it is modified to adapt with the semantic segmentation, namely,</p>
<ul>
<li>
<strong>Hierarchical Feature Representation</strong>: Unlike ViT that can only generate a single-resolution feature
map, MiT generate multi-level features to adapt with the semantic segmentation. We can see the multi-level features idea is one of the most important ideas for the semantic segmentation, for example: HRNET, PSPNet, DeepLab, FPN, ...</li>
<li>
<strong>Overlapped Patch Merging</strong>: In Vision Transformer, a image input is splitted into <strong>partition</strong> patches. With the Mix Transformer, a image input is also splitted into patches, but there are overlapping.</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">OverlapPatchMerging</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">patch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">overlap_size</span><span class="p">:</span> <span class="nb">int</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                <span class="n">in_channels</span><span class="p">,</span>
                <span class="n">out_channels</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="n">patch_size</span><span class="p">,</span>
                <span class="n">stride</span><span class="o">=</span><span class="n">overlap_size</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="n">patch_size</span> <span class="o">//</span> <span class="mi">2</span><span class="p">,</span>
                <span class="n">bias</span><span class="o">=</span><span class="kc">False</span>
            <span class="p">),</span>
            <span class="n">LayerNorm2d</span><span class="p">(</span><span class="n">out_channels</span><span class="p">)</span>
        <span class="p">)</span>
</pre></div>
<table>
<thead>
<tr>
<th style="text-align:center">Partition Patch</th>
<th style="text-align:center">Overlapped Patch</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><img align="center" width="300" src="https://habrastorage.org/webt/en/6i/5b/en6i5bbonwp5cpva70awswkefie.png"></td>
<td style="text-align:center"><img align="center" width="300" src="https://habrastorage.org/webt/xj/gu/ps/xjgupsjrgxbxrtaqktzsia7ovsm.png"></td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<strong>Efficient Self-Attention</strong>: The main computation bottleneck of the encoders is the self-attention layer. The <code>Efficient Self-Attention</code> is implemented as the following:</li>
</ul>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">EfficientMultiHeadAttention</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">reduction_ratio</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">num_heads</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">8</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reducer</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                <span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="n">reduction_ratio</span><span class="p">,</span> <span class="n">stride</span><span class="o">=</span><span class="n">reduction_ratio</span>
            <span class="p">),</span>
            <span class="n">LayerNorm2d</span><span class="p">(</span><span class="n">channels</span><span class="p">),</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">att</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MultiheadAttention</span><span class="p">(</span>
            <span class="n">channels</span><span class="p">,</span> <span class="n">num_heads</span><span class="o">=</span><span class="n">num_heads</span><span class="p">,</span> <span class="n">batch_first</span><span class="o">=</span><span class="kc">True</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">_</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">h</span><span class="p">,</span> <span class="n">w</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span>
        <span class="n">reduced_x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">reducer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="c1"># attention needs tensor of shape (batch, sequence_length, channels)</span>
        <span class="n">reduced_x</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">reduced_x</span><span class="p">,</span> <span class="s2">"b c h w -&gt; b (h w) c"</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s2">"b c h w -&gt; b (h w) c"</span><span class="p">)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">att</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">reduced_x</span><span class="p">,</span> <span class="n">reduced_x</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="c1"># reshape it back to (batch, channels, height, width)</span>
        <span class="n">out</span> <span class="o">=</span> <span class="n">rearrange</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="s2">"b (h w) c -&gt; b c h w"</span><span class="p">,</span> <span class="n">h</span><span class="o">=</span><span class="n">h</span><span class="p">,</span> <span class="n">w</span><span class="o">=</span><span class="n">w</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">out</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<ul>
<li>
<strong>Mix-FFN</strong>: Authors don't use the  positional encoding (PE) to introduce the location information as in the 
ViT. That is from the argument that positional encoding is actually not necessary for semantic segmentation. One intorduces the <code>Mix-FFN</code> is defined as: </li>
</ul>
<p>
$$x_{out} = MLP(GELU(CONV_{3 \times 3}(MLP(x_{in})))) + x_{in}$$
</p>
<p>More precisely,</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MixMLP</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">expansion</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">4</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="c1"># dense layer</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
            <span class="c1"># depth wise conv</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span>
                <span class="n">channels</span><span class="p">,</span>
                <span class="n">channels</span> <span class="o">*</span> <span class="n">expansion</span><span class="p">,</span>
                <span class="n">kernel_size</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span>
                <span class="n">groups</span><span class="o">=</span><span class="n">channels</span><span class="p">,</span>
                <span class="n">padding</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
            <span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">GELU</span><span class="p">(),</span>
            <span class="c1"># dense layer</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">channels</span> <span class="o">*</span> <span class="n">expansion</span><span class="p">,</span> <span class="n">channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="3.2-Decoder">
<a class="anchor" href="#3.2-Decoder" aria-hidden="true"><span class="octicon octicon-link"></span></a>3.2 Decoder<a class="anchor-link" href="#3.2-Decoder"> </a>
</h3>
<p>The Mix Transformer do well for the encoder part, then for the decoder part, we use All-MLP to fuse the multi-level features of the encoder part.</p>
<p><!-- <img align="center" width="500"  src="https://habrastorage.org/webt/jg/-d/29/jg-d29v79uubc9mh2djmt12xzvs.png"> -->
<img src="https://habrastorage.org/webt/jg/-d/29/jg-d29v79uubc9mh2djmt12xzvs.png" alt="" title="The architecture of the decoder"></p>
<p>Each Block of MLP-ll has the following form:</p>
<div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SegFormerDecoderBlock</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">in_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">scale_factor</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">UpsamplingBilinear2d</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="n">scale_factor</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="n">in_channels</span><span class="p">,</span> <span class="n">out_channels</span><span class="p">,</span> <span class="n">kernel_size</span><span class="o">=</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">)</span>
</pre></div>
<p>For the MLP-All. 
Now we can jump to the next part.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="4.-Traing-the-Segformer-model-with-Pytorch-Lightning-and-HuggingFace.">
<a class="anchor" href="#4.-Traing-the-Segformer-model-with-Pytorch-Lightning-and-HuggingFace." aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Traing the Segformer model with Pytorch Lightning and HuggingFace.<a class="anchor-link" href="#4.-Traing-the-Segformer-model-with-Pytorch-Lightning-and-HuggingFace."> </a>
</h2>
<p>In this part we will discover how to train the Segformer model. In the <a href="https://hphuongdhsp.github.io/ml-blog/2022/08/03/segmentation-model-part3.html">part III</a>, we have used the <strong>segmentation_models_pytorch</strong> to build a <strong>Unet</strong> model to deal with the nail the segmentation problem. Unfortunately, the segmentation_models_pytorch don't yet implement <strong>SegFormer</strong> model. There are some open sources that implement the <strong>SegFormer</strong> model:</p>
<ul>
<li><a href="https://github.com/open-mmlab/mmsegmentation">MMSegmentation</a></li>
<li><a href="https://github.com/huggingface/transformers">Transformers - HuggingFace</a></li>
<li>
<a href="https://github.com/FrancescoSaverioZuppichini/SegFormer">Implementing SegFormer in PyTorch</a> 
The first one is the officinal source code, but the model sticks with the <strong>MMSegmentation</strong> platform. It will be difficulty for unfamiliar people of the <strong>MMSegmentation</strong> platform. The third one is reimplemented from scratch, but the model is not trained for any data. So we cannot profit the pretrained weights. We choose the second one that is implemented and trained by the <strong>HuggingFace</strong> team. </li>
</ul>
<p>We will reuse the datapipeline and modelpipeline of the <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/tree/master/Part%203-Pytorch%20Lightning">third part</a> of the tutorial series except that we will use the <code>transformer</code> library to build the Segformer model.</p>
<div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">SegformerForSemanticSegmentation</span>

<span class="k">class</span> <span class="nc">SegFormer</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span> <span class="n">pretrained</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">"nvidia/segformer-b4-finetuned-ade-512-512"</span><span class="p">,</span> <span class="n">size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">512</span><span class="p">,</span> <span class="n">num_labels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">9</span>
    <span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">segformer</span> <span class="o">=</span> <span class="n">SegformerForSemanticSegmentation</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
            <span class="n">pretrained</span><span class="p">,</span> <span class="n">ignore_mismatched_sizes</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">num_labels</span><span class="o">=</span><span class="n">num_labels</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">size</span> <span class="o">=</span> <span class="n">size</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
        <span class="n">outputs</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">segformer</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

        <span class="n">upsampled_logits</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span>
            <span class="n">outputs</span><span class="o">.</span><span class="n">logits</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="n">mode</span><span class="o">=</span><span class="s2">"bilinear"</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="kc">False</span>
        <span class="p">)</span>
        <span class="k">return</span> <span class="n">upsampled_logits</span>
</pre></div>
<p>Here we use the pretrained of <code>"nvidia/segformer-b4-finetuned-ade-512-512"</code>. It means that:</p>
<ul>
<li>MiT-B4 Mix-Transformer is used to build the encoder part.</li>
<li>Weight is trained on the ADE 20K dataset.</li>
<li>Size of image = 512<blockquote>
<p>Note that the output of the <strong>SegFormer</strong> model is (128,128). We the use the resize function <code>torch.nn.functional.interpolate</code>. We can totally replace the resize function with any other weighted function:<code>nn.ConvTranspose2d</code>.</p>
</blockquote>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We then can define the <code>model module</code> and <code>data module</code> as the same in the part III:</p>
<div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">SegFormer</span><span class="p">(</span><span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">encoder_name</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">size</span><span class="p">,</span> <span class="n">config</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">classes</span><span class="p">)</span>

<span class="n">datamodule</span> <span class="o">=</span> <span class="n">NailSegmentation</span><span class="p">(</span>
    <span class="n">data_root</span><span class="o">=</span><span class="n">data_root</span><span class="p">,</span>
    <span class="n">csv_path</span><span class="o">=</span><span class="n">csv_path</span><span class="p">,</span>
    <span class="n">test_path</span><span class="o">=</span><span class="s2">""</span><span class="p">,</span>
    <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span>
    <span class="n">num_workers</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
    <span class="p">)</span>

<span class="n">model_lighning</span> <span class="o">=</span> <span class="n">LitNailSegmentation</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">learning_rate</span><span class="o">=</span><span class="n">config</span><span class="o">.</span><span class="n">training</span><span class="o">.</span><span class="n">learning_rate</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And run the <code>Trainer</code> API</p>
<div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span><span class="n">args</span><span class="p">)</span>
<span class="n">trainer</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model_lighning</span><span class="p">,</span>
    <span class="n">datamodule</span><span class="o">=</span><span class="n">datamodule</span>
<span class="p">)</span>
</pre></div>
<p><strong>We can find the full source code at <a href="https://github.com/hphuongdhsp/Segmentation-Tutorial/tree/master/Part%206-Pytorch%20with%20Huggingface">github</a></strong></p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>References:</p>
<ul>
<li><a href="https://github.com/NVlabs/SegFormer">SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers</a></li>
<li><a href="https://huggingface.co/docs/transformers/model_doc/segformer">SegFormer</a></li>
<li><a href="https://towardsdatascience.com/implementing-segformer-in-pytorch-8f4705e2ed0e">Implementing SegFormer in PyTorch</a></li>
</ul>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="hphuongdhsp/ml-blog"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/ml-blog/2022/08/07/segmentation-model-part6.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/ml-blog/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/ml-blog/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/ml-blog/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>share2learn machine learning blog</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/hphuongdhsp" target="_blank" title="hphuongdhsp"><svg class="svg-icon grey"><use xlink:href="/ml-blog/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://twitter.com/hphuongdhsp" target="_blank" title="hphuongdhsp"><svg class="svg-icon grey"><use xlink:href="/ml-blog/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
